{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d337656d-5834-4357-af72-f1e58db8437d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TRAIN (44321 items)===\n",
      "{\n",
      "  \"decomposition\": \"return homepages ;return #1 of  PVLDB\",\n",
      "  \"operators\": \"['select', 'filter']\",\n",
      "  \"question_id\": \"ACADEMIC_train_0\",\n",
      "  \"question_text\": \"return me the homepage of PVLDB . \",\n",
      "  \"split\": \"train\"\n",
      "}\n",
      "{\n",
      "  \"decomposition\": \"return homepages ;return #1 of  H. V. Jagadish\",\n",
      "  \"operators\": \"['select', 'filter']\",\n",
      "  \"question_id\": \"ACADEMIC_train_1\",\n",
      "  \"question_text\": \"return me the homepage of \\\" H. V. Jagadish \\\" . \",\n",
      "  \"split\": \"train\"\n",
      "}\n",
      "{\n",
      "  \"decomposition\": \"return references ;return #1 of  Making database systems usable ;return number of  #2\",\n",
      "  \"operators\": \"['select', 'filter', 'aggregate']\",\n",
      "  \"question_id\": \"ACADEMIC_train_10\",\n",
      "  \"question_text\": \"return me the number of references of \\\" Making database systems usable \\\" . \",\n",
      "  \"split\": \"train\"\n",
      "}\n",
      "=== DEV (100 items)===\n",
      "{\n",
      "  \"decomposition\": \"return flights ;return #1 from  denver ;return #2 to philadelphia ;return #3 if  available\",\n",
      "  \"operators\": \"['select', 'filter', 'filter', 'filter']\",\n",
      "  \"question_id\": \"ATIS_dev_0\",\n",
      "  \"question_text\": \"what flights are available tomorrow from denver to philadelphia \",\n",
      "  \"split\": \"dev\"\n",
      "}\n",
      "{\n",
      "  \"decomposition\": \"return flights ;return #1 that  are nonstop ;return #2 from  oakland ;return #3 to philadelphia ;return #4 arriving between 5 and  6pm\",\n",
      "  \"operators\": \"['select', 'filter', 'filter', 'filter', 'filter']\",\n",
      "  \"question_id\": \"ATIS_dev_170\",\n",
      "  \"question_text\": \"what nonstop flights are available from oakland to philadelphia arriving between 5 and 6pm \",\n",
      "  \"split\": \"dev\"\n",
      "}\n",
      "{\n",
      "  \"decomposition\": \"return round trips airfares ;return #1 from  pittsburghs ;return #2 to boston ;return the  least expensive of  #3\",\n",
      "  \"operators\": \"['select', 'filter', 'filter', 'project']\",\n",
      "  \"question_id\": \"ATIS_dev_245\",\n",
      "  \"question_text\": \"i'd like information on the least expensive airfare round trip from pittsburgh to boston \",\n",
      "  \"split\": \"dev\"\n",
      "}\n",
      "=== ANTIDEV (100 items)===\n",
      "{\n",
      "  \"decomposition\": \"return #2 to philadelphia ;return flights ;return #1 from  denver ;return #3 if  available\",\n",
      "  \"operators\": \"['select', 'filter', 'filter', 'filter']\",\n",
      "  \"question_id\": \"ATIS_dev_0\",\n",
      "  \"question_text\": \"what flights are available tomorrow from denver to philadelphia \",\n",
      "  \"split\": \"dev\"\n",
      "}\n",
      "{\n",
      "  \"decomposition\": \"return flights ;return #1 that  are nonstop philadelphia #2 from  oakland ;return #3 to ;return ;return #4 arriving between 5 and  6pm\",\n",
      "  \"operators\": \"['select', 'filter', 'filter', 'filter', 'filter']\",\n",
      "  \"question_id\": \"ATIS_dev_170\",\n",
      "  \"question_text\": \"what nonstop flights are available from oakland to philadelphia arriving between 5 and 6pm \",\n",
      "  \"split\": \"dev\"\n",
      "}\n",
      "{\n",
      "  \"decomposition\": \"return round trips airfares ;return #1 from  pittsburghs ;return #2 to boston ;the return expensive of least  #3 \",\n",
      "  \"operators\": \"['select', 'filter', 'filter', 'project']\",\n",
      "  \"question_id\": \"ATIS_dev_245\",\n",
      "  \"question_text\": \"i'd like information on the least expensive airfare round trip from pittsburgh to boston \",\n",
      "  \"split\": \"dev\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "import os\n",
    "import pandas\n",
    "import json\n",
    "import random\n",
    "github_path = \"https://raw.githubusercontent.com/allenai/Break/refs/heads/master/break_dataset/QDMR\"\n",
    "data = {}\n",
    "for name in ['train', 'dev', 'test']:\n",
    "    url = os.path.join(github_path, '{}.csv'.format(name))\n",
    "    filepath = '{}.csv'.format(name)\n",
    "    if not os.path.isfile(filepath):\n",
    "      os.system('wget {}'.format(url))\n",
    "    assert os.path.isfile(filepath)\n",
    "    lines = pandas.read_csv(open(filepath, 'r'))\n",
    "    data[name] = json.loads(lines.to_json(orient='records'))\n",
    "    \n",
    "def jumble(decomp, ii):\n",
    "    clause_separator = ' ;'\n",
    "    word_separator = ' '\n",
    "    if ii%3==0:\n",
    "        clauses = decomp.split(clause_separator)\n",
    "        random.shuffle(clauses)\n",
    "        decomp = clause_separator.join(clauses)\n",
    "    elif ii%3==1:\n",
    "        words = decomp.split(word_separator)\n",
    "        indices = (0,0)\n",
    "        while indices[0] == indices[1]:\n",
    "            indices = (random.randrange(len(words)), random.randrange(len(words)))\n",
    "        tmp = words[indices[0]]\n",
    "        words[indices[0]] = words[indices[1]]\n",
    "        words[indices[1]] = tmp\n",
    "        decomp = ' '.join(words)\n",
    "    elif ii%3==2:\n",
    "        clauses = decomp.split(clause_separator)\n",
    "        clauses = [y.split(word_separator) for y in clauses]\n",
    "        index = random.randrange(len(clauses))\n",
    "        random.shuffle(clauses[index])\n",
    "        decomp = clause_separator.join(word_separator.join(c) for c in clauses)\n",
    "    return decomp\n",
    "\n",
    "def corrupt(data):\n",
    "    # make a negative example for the grammar\n",
    "    # three types of corruption:\n",
    "    # 1. change order of clauses\n",
    "    # 2. switch 2 words\n",
    "    # 3. shuffle word order inside a clause\n",
    "    random.seed(0)\n",
    "    output = []\n",
    "    for z in data:\n",
    "        assert isinstance(z, dict)\n",
    "        output.append(dict(z))\n",
    "    assert output == data\n",
    "    for ii, x in enumerate(output):\n",
    "        assert data[ii] == output[ii]\n",
    "        decomp = x['decomposition']\n",
    "        new_decomp = decomp\n",
    "        while decomp == new_decomp:\n",
    "            new_decomp = jumble(decomp, ii)\n",
    "        assert output[ii]['decomposition'] != new_decomp\n",
    "        output[ii]['decomposition'] = str(new_decomp)\n",
    "        assert data[ii] != output[ii]\n",
    "    return output\n",
    "    \n",
    "# reduce size of dev; provide smaller canonical sets\n",
    "N = 100\n",
    "step = len(data['dev'])//N\n",
    "data['dev'] = data['dev'][0:len(data['dev']):step]\n",
    "data['dev'] = data['dev'][:N]\n",
    "data['antidev'] = corrupt(data['dev'])\n",
    "assert data['dev'] != data['antidev']\n",
    "for name in ['train', 'dev', 'antidev']:\n",
    "    print('=== {} ({} items)==='.format(name.upper(), len(data[name])))\n",
    "    print('\\n'.join(json.dumps(x, indent=2, sort_keys=True) for x in data[name][:3]))\n",
    "max_length_train = max(len(x['decomposition'].split()) for x in data['train'])\n",
    "avg_length_train = sum(len(x['decomposition'].split()) for x in data['train'])/len(data['train'])\n",
    "var_length_train = sum((len(x['decomposition'].split())-avg_length_train)**2 for x in data['train'])/len(data['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "210e8ee3-efb3-4346-b440-653d30d94e60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Grammar\n",
    "import lark\n",
    "import tqdm\n",
    "def get_grammar_parse_rate(grammar, data, hard=False):\n",
    "    p = lark.Lark(grammar)\n",
    "    positives, negatives = 0, 0\n",
    "    for x in tqdm.tqdm(data):\n",
    "        parse=None\n",
    "        decomp = x['decomposition'] + '\\n' # add final newline as end of generation token\n",
    "        if hard:\n",
    "            print(decomp)\n",
    "            parse = p.parse(decomp)\n",
    "        else:\n",
    "            try:\n",
    "                parse = p.parse(decomp)\n",
    "            except:\n",
    "                pass\n",
    "        #print(coverage)\n",
    "        #assert False\n",
    "        parsed = int(parse is not None)\n",
    "        positives += parsed\n",
    "        negatives += (1-parsed)\n",
    "    assert positives + negatives == len(data)\n",
    "    return positives, negatives\n",
    "\n",
    "def get_grammar_metrics(grammar):\n",
    "    output = {}\n",
    "    tp, fn = get_grammar_parse_rate(grammar, data['dev'])\n",
    "    fp, tn = get_grammar_parse_rate(grammar, data['antidev'])\n",
    "    output['precision'] = tp/(tp+fp)\n",
    "    output['recall'] = tp/(tp+fn)\n",
    "    output['f1'] = 2*tp/(2*tp+fp+fn)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eefcb42a-4e0e-442f-aec9-295d7923a574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grammar\n",
    "def make_ngram_grammar(data, vocab_fraction, n=3):\n",
    "    all_ngrams = {}\n",
    "    for x in data:\n",
    "        words = x['decomposition'].split()\n",
    "        assert '' not in words, words\n",
    "        for nn in range(1,n+1):\n",
    "            all_ngrams.setdefault(nn, {})\n",
    "            for ii,_ in enumerate(words):\n",
    "                ngram = ' '.join(words[ii:ii+nn])\n",
    "                all_ngrams[nn].setdefault(ngram,0)\n",
    "                all_ngrams[nn][ngram]+=1\n",
    "    ngrams = [None for _ in range(n)]\n",
    "    for nn in range(1,n+1):\n",
    "        num_items = max(int(vocab_fraction/n*len(all_ngrams[nn])), 1)\n",
    "        ngram_list = filter(lambda x: x[0] not in ['return', ';return', ' ', ';'], all_ngrams[nn].items())\n",
    "        ngram_list = sorted(ngram_list, key=lambda x: (x[1], x[0]), reverse=True)[:num_items] # only keep top words\n",
    "        ngram_list = sorted(map(lambda x: x[0], ngram_list))\n",
    "        ngram_list = ' | '.join('\"{}\"'.format(x) for x in ngram_list)\n",
    "        ngrams[nn-1] = ngram_list\n",
    "    assert all(x is not None for x in ngrams)\n",
    "    ngrams = ' | '.join('{}'.format(x) for x in ngrams)\n",
    "    # Be careful to write \\\\n and not \\n when declaring a grammar directly as a string\n",
    "    # sometimes there are double whitespaces so I'm accounting for that\n",
    "    grammar = \"\"\"\n",
    "    NEWLINE: \"\\\\n\"\n",
    "    \n",
    "    SPACE: \" \" | \"  \" | \"   \"\n",
    "    \n",
    "    ?start: sentence NEWLINE\n",
    "\n",
    "    RETURN: \"return\"\n",
    "\n",
    "    SEPARATOR: \" ;\"\n",
    "\n",
    "    ?sentence: RETURN SPACE expression (SEPARATOR RETURN SPACE expression)~0..9\n",
    "    \n",
    "    ?expression: word (SPACE word)~0..9\n",
    "    \n",
    "    ?word: \"\"\"+ngrams\n",
    "    return grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a5a98a6-aad7-4f05-a84a-467e1bd66004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few-shot retriever\n",
    "from rank_bm25 import BM25Okapi\n",
    "class FewShotRetriever:\n",
    "    def __init__(self, data_set):\n",
    "        # data_set contains items from the training set\n",
    "        assert isinstance(data_set, list)\n",
    "        assert all(isinstance(x, dict) for x in data_set)\n",
    "        self.data = [(x['question_text'], x['decomposition']) for x in data_set]\n",
    "        self.bm25 = None\n",
    "    def build_index(self):\n",
    "        self.corpus = [x[0] for x in self.data]\n",
    "        tokenized_corpus = [doc.split(\" \") for doc in self.corpus]\n",
    "        self.bm25 = BM25Okapi(tokenized_corpus)\n",
    "    def get_samples(self, query, n=4):\n",
    "        tokenized_query = query.split(\" \")\n",
    "        top_n = self.bm25.get_top_n(tokenized_query, self.data, n=n)\n",
    "        return top_n\n",
    "        \n",
    "retriever = FewShotRetriever(data['train'])\n",
    "retriever.build_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e586c04-f5f2-45af-8bde-cacb747824fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "import outlines\n",
    "from outlines.generate.api import GenerationParameters\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "MAX_TOKENS = int(avg_length_train+3*(var_length_train**.5))\n",
    "class Model:\n",
    "    def __init__(self, model_name, retriever, grammar, n_few_shot=8, max_tokens=MAX_TOKENS):\n",
    "        assert isinstance(retriever, FewShotRetriever)\n",
    "        self.retriever=retriever\n",
    "        self.grammar=grammar\n",
    "        if self.grammar is not None:\n",
    "            assert isinstance(grammar, str)\n",
    "        assert isinstance(max_tokens, int)\n",
    "        self.max_tokens = max_tokens\n",
    "        assert isinstance(model_name, str)\n",
    "        if self.grammar is None:\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "            self.model = AutoModelForCausalLM.from_pretrained(model_name, pad_token_id=self.tokenizer.eos_token_id)\n",
    "        else:\n",
    "            self.model = outlines.models.transformers(model_name)\n",
    "            self.generator=outlines.generate.cfg(self.model, self.grammar)\n",
    "        assert isinstance(n_few_shot, int)\n",
    "        self.n_few_shot=n_few_shot\n",
    "    def generate(self, input_strings):\n",
    "        if self.grammar is None:\n",
    "            return self.generate_unconstrained(input_strings)\n",
    "        else:\n",
    "            return self.generate_constrained(input_strings)\n",
    "    def generate_unconstrained(self, input_strings):\n",
    "        assert isinstance(input_strings, list)\n",
    "        assert all(isinstance(ii, str) for ii in input_strings)\n",
    "        prompts = self.make_prompts(input_strings)\n",
    "        pipe = pipeline(\n",
    "            \"text-generation\", \n",
    "            model=self.model,\n",
    "            tokenizer=self.tokenizer\n",
    "        )\n",
    "        generation_args = {\n",
    "            \"max_new_tokens\": self.max_tokens,\n",
    "            \"return_full_text\": False,\n",
    "            \"do_sample\": False,\n",
    "            \"stop_strings\": ['\\n'],\n",
    "            \"tokenizer\": self.tokenizer,\n",
    "            \"pad_token_id\": self.tokenizer.eos_token_id\n",
    "\n",
    "        } \n",
    "        output = pipe(prompts, **generation_args)\n",
    "        output = [oo[0] for oo in output] # remove final whitespace and end-of-line\n",
    "        assert len(output) == len(prompts)\n",
    "        output = [{'prompt': prompt, 'lm_output': x['generated_text'].strip()} for x, prompt in zip(output, prompts)]\n",
    "        return output\n",
    "    def generate_constrained(self, input_strings):\n",
    "        assert isinstance(input_strings, list)\n",
    "        assert all(isinstance(ii, str) for ii in input_strings)\n",
    "        prompts = self.make_prompts(input_strings)\n",
    "        lm_outputs = self.generator(prompts, max_tokens=self.max_tokens, stop_at=['\\n'])\n",
    "        output = [{'prompt': prompt, 'max_tokens': self.max_tokens, 'lm_output': lmo.strip()}\n",
    "                  for lmo,prompt in zip(lm_outputs, prompts)]\n",
    "        return output\n",
    "    def make_prompt(self, input_string):\n",
    "        samples = self.retriever.get_samples(input_string, n=self.n_few_shot)\n",
    "        #assert len(samples) == self.n_few_shot\n",
    "        prompt = [\"Question: {}\\nAnswer: {}\".format(x, y) for x, y in samples]\n",
    "        prompt.append(\"Question: {}\\nAnswer: \".format(input_string))\n",
    "        prompt = '\\n'.join(prompt)\n",
    "        return prompt\n",
    "    def make_prompts(self, input_strings):\n",
    "        prompts = [self.make_prompt(input_string) for input_string in input_strings]\n",
    "        return prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f453a77-fe89-41ea-869b-2749bdeea420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run on validation\n",
    "import tqdm\n",
    "def inference(model, data, batch_size=1):\n",
    "    output = []\n",
    "    for ii in tqdm.tqdm(range(0, len(data), batch_size)):\n",
    "        batch = data[ii:ii+batch_size]\n",
    "        lm_output=model.generate([xx['question_text'] for xx in batch])\n",
    "        output.extend([{'decomposition': yy['lm_output'], 'question': xx['question_text'], 'gold': xx['decomposition'], 'id': xx['question_id']}\n",
    "                   for xx, yy in zip(batch, lm_output)])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c12aa1c1-6dca-4a78-9e3f-ff87abb57178",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluator for Break dataset\n",
    "from scripts.evaluate_predictions import evaluate\n",
    "from evaluation.decomposition import Decomposition\n",
    "def run_eval(model, batch_size=10):\n",
    "    output = inference(model, data['dev'], batch_size=batch_size)\n",
    "    ids = [oo['id'] for oo in output]\n",
    "    questions = [oo['question'] for oo in output]\n",
    "    decompositions = [Decomposition.from_str(oo['decomposition']) for oo in output]\n",
    "    golds = [Decomposition.from_str(oo['gold']) for oo in output]\n",
    "    metadata=None\n",
    "    output_path_base = '/home/nils/Desktop/code-generation-lab'\n",
    "    metrics = evaluate(ids, questions, decompositions, golds, metadata, output_path_base)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0909768-ea76-4aa9-82bb-ddf385e998fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [10:07<00:00, 60.72s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:02<00:00, 39.82it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 70350.62it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:02<00:00, 36.14it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:02<00:00, 35.16it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 5306.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating example #0\n",
      "\tid: ATIS_dev_0\n",
      "\tquestion: what flights are available tomorrow from denver to philadelphia \n",
      "\tgold: return flights ;return #1 from denver ;return #2 to philadelphia ;return #3 if available\n",
      "\tprediction: 1000000000000000000000000000000000000000000000000000000000\n",
      "\texact_match: 0\n",
      "\tmatch: 0.0\n",
      "\tstructural_match: 1.0\n",
      "\tsari: 0.431\n",
      "\tged: 1.0\n",
      "\tnormalized_exact_match: 0\n",
      "\tnormalized_match: 0.0\n",
      "\tnormalized_structural_match: 0.0\n",
      "\tnormalized_sari: 0.542\n",
      "evaluating example #1\n",
      "\tid: ATIS_dev_170\n",
      "\tquestion: what nonstop flights are available from oakland to philadelphia arriving between 5 and 6pm \n",
      "\tgold: return flights ;return #1 that are nonstop ;return #2 from oakland ;return #3 to philadelphia ;return #4 arriving between 5 and 6pm\n",
      "\tprediction: 5pm to 6pm ; 6pm to 7pm ; 7pm to 8pm ; 8pm to 9pm ; 9pm to 10pm ; 10pm to 11pm ; 11pm to 12\n",
      "\texact_match: 0\n",
      "\tmatch: 0.113\n",
      "\tstructural_match: 1.0\n",
      "\tsari: 0.224\n",
      "\tged: 0.887\n",
      "\tnormalized_exact_match: 0\n",
      "\tnormalized_match: 0.217\n",
      "\tnormalized_structural_match: 0.37\n",
      "\tnormalized_sari: 0.424\n",
      "evaluating example #2\n",
      "\tid: ATIS_dev_245\n",
      "\tquestion: i'd like information on the least expensive airfare round trip from pittsburgh to boston \n",
      "\tgold: return round trips airfares ;return #1 from pittsburghs ;return #2 to boston ;return the least expensive of #3\n",
      "\tprediction: 1000000000000000000000000000000000000000000000000000000000\n",
      "\texact_match: 0\n",
      "\tmatch: 0.0\n",
      "\tstructural_match: 1.0\n",
      "\tsari: 0.354\n",
      "\tged: 1.0\n",
      "\tnormalized_exact_match: 0\n",
      "\tnormalized_match: 0.0\n",
      "\tnormalized_structural_match: 0.0\n",
      "\tnormalized_sari: 0.444\n",
      "evaluating example #3\n",
      "\tid: ATIS_dev_319\n",
      "\tquestion: i need a flight from pittsburgh to new york city \n",
      "\tgold: return flights ;return #1 from pittsburgh ;return #2 to new york city\n",
      "\tprediction: 1st flight ; 2nd flight ; 3rd flight ; 4th flight ; 5th flight ; 6th flight ; 7th flight ; 8th flight ; 9th flight ; 10th flight ; 11th flight ; 1\n",
      "\texact_match: 0\n",
      "\tmatch: 0.12\n",
      "\tstructural_match: 1.0\n",
      "\tsari: 0.221\n",
      "\tged: 0.88\n",
      "\tnormalized_exact_match: 0\n",
      "\tnormalized_match: 0.232\n",
      "\tnormalized_structural_match: 0.34\n",
      "\tnormalized_sari: 0.57\n",
      "evaluating example #4\n",
      "\tid: ATIS_dev_391\n",
      "\tquestion: is there a flight between san francisco and boston with a stopover in dallas fort worth \n",
      "\tgold: return flights ;return #1 between san francisco ;return #2 and boston ;return #3 with a stopover in dallas fort worth\n",
      "\tprediction: 1st stopover in dallas fort worth ; 2nd stopover in san francisco ; 3rd stopover in dallas fort worth\n",
      "\texact_match: 0\n",
      "\tmatch: 0.311\n",
      "\tstructural_match: 1.0\n",
      "\tsari: 0.454\n",
      "\tged: 0.689\n",
      "\tnormalized_exact_match: 0\n",
      "\tnormalized_match: 0.333\n",
      "\tnormalized_structural_match: 0.4\n",
      "\tnormalized_sari: 0.653\n",
      "\n",
      "overall scores:\n",
      "exact_match score:\tmean 0.000\tmax 0.000\tmin 0.000\n",
      "match score:\tmean 0.256\tmax 0.875\tmin 0.000\n",
      "structural_match score:\tmean 1.000\tmax 1.000\tmin 1.000\n",
      "sari score:\tmean 0.474\tmax 0.918\tmin 0.163\n",
      "ged score:\tmean 0.744\tmax 1.000\tmin 0.125\n",
      "normalized_exact_match score:\tmean 0.000\tmax 0.000\tmin 0.000\n",
      "normalized_match score:\tmean 0.262\tmax 0.762\tmin 0.000\n",
      "normalized_structural_match score:\tmean 0.345\tmax 0.842\tmin 0.000\n",
      "normalized_sari score:\tmean 0.616\tmax 0.856\tmin 0.369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Model without constraints\n",
    "unconstrained_model = Model(\"HuggingFaceTB/SmolLM-135M\", retriever, None, n_few_shot=1)\n",
    "m = run_eval(unconstrained_model)\n",
    "del unconstrained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68a241e2-5162-456f-8ac9-521bdf2afa37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [01:16<00:00,  1.30it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [01:16<00:00,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.625, 'recall': 0.35, 'f1': 0.44871794871794873}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Model with unigram grammar\n",
    "unigram_grammar = make_ngram_grammar(data['train'], .1, n=1)\n",
    "unigram_grammar_metrics = get_grammar_metrics(unigram_grammar)\n",
    "print(unigram_grammar_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc1eb4fb-3653-4c13-849d-b44e832e3e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nils/anaconda3/envs/code-generation-lab/lib/python3.11/site-packages/outlines/fsm/guide.py:112: UserWarning: Outlines' public *community-contributed* CFG structured generation is experimental. Please review https://dottxt-ai.github.io/outlines/latest/reference/generation/cfg#disclaimer\n",
      "  warnings.warn(\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [22:28<00:00, 134.85s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:02<00:00, 40.08it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 70021.77it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:02<00:00, 36.73it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:02<00:00, 35.11it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 3618.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating example #0\n",
      "\tid: ATIS_dev_0\n",
      "\tquestion: what flights are available tomorrow from denver to philadelphia \n",
      "\tgold: return flights ;return #1 from denver ;return #2 to philadelphia ;return #3 if available\n",
      "\tprediction: return flights ;return #1 from denver ;return #2 to philadelphia ;return #3 that are on monday\n",
      "\texact_match: 0\n",
      "\tmatch: 0.857\n",
      "\tstructural_match: 1.0\n",
      "\tsari: 0.881\n",
      "\tged: 0.143\n",
      "\tnormalized_exact_match: 0\n",
      "\tnormalized_match: 0.833\n",
      "\tnormalized_structural_match: 0.818\n",
      "\tnormalized_sari: 0.884\n",
      "evaluating example #1\n",
      "\tid: ATIS_dev_170\n",
      "\tquestion: what nonstop flights are available from oakland to philadelphia arriving between 5 and 6pm \n",
      "\tgold: return flights ;return #1 that are nonstop ;return #2 from oakland ;return #3 to philadelphia ;return #4 arriving between 5 and 6pm\n",
      "\tprediction: return flights ;return #1 from oakland ;return #2 from philadelphia ;return #3 from philadelphia ;return #4 from philadelphia ;return #5 from philadelphia ;return #6 from philadelphia\n",
      "\texact_match: 0\n",
      "\tmatch: 0.638\n",
      "\tstructural_match: 1.0\n",
      "\tsari: 0.413\n",
      "\tged: 0.362\n",
      "\tnormalized_exact_match: 0\n",
      "\tnormalized_match: 0.69\n",
      "\tnormalized_structural_match: 0.6\n",
      "\tnormalized_sari: 0.63\n",
      "evaluating example #2\n",
      "\tid: ATIS_dev_245\n",
      "\tquestion: i'd like information on the least expensive airfare round trip from pittsburgh to boston \n",
      "\tgold: return round trips airfares ;return #1 from pittsburghs ;return #2 to boston ;return the least expensive of #3\n",
      "\tprediction: return #1 from boston to pittsburgh ;return #2 from pittsburgh to boston ;return #3 from boston to pittsburgh\n",
      "\texact_match: 0\n",
      "\tmatch: 0.553\n",
      "\tstructural_match: 1.0\n",
      "\tsari: 0.439\n",
      "\tged: 0.447\n",
      "\tnormalized_exact_match: 0\n",
      "\tnormalized_match: 0.471\n",
      "\tnormalized_structural_match: 0.385\n",
      "\tnormalized_sari: 0.653\n",
      "evaluating example #3\n",
      "\tid: ATIS_dev_319\n",
      "\tquestion: i need a flight from pittsburgh to new york city \n",
      "\tgold: return flights ;return #1 from pittsburgh ;return #2 to new york city\n",
      "\tprediction: return flights ;return #1 from pittsburgh ;return #2 to new york city ;return #3 that are tomorrow\n",
      "\texact_match: 0\n",
      "\tmatch: 0.821\n",
      "\tstructural_match: 1.0\n",
      "\tsari: 0.915\n",
      "\tged: 0.179\n",
      "\tnormalized_exact_match: 0\n",
      "\tnormalized_match: 0.767\n",
      "\tnormalized_structural_match: 0.828\n",
      "\tnormalized_sari: 0.902\n",
      "evaluating example #4\n",
      "\tid: ATIS_dev_391\n",
      "\tquestion: is there a flight between san francisco and boston with a stopover in dallas fort worth \n",
      "\tgold: return flights ;return #1 between san francisco ;return #2 and boston ;return #3 with a stopover in dallas fort worth\n",
      "\tprediction: return flight ;return #1 with stopover in dallas fort worth\n",
      "\texact_match: 0\n",
      "\tmatch: 0.632\n",
      "\tstructural_match: 1.0\n",
      "\tsari: 0.49\n",
      "\tged: 0.368\n",
      "\tnormalized_exact_match: 0\n",
      "\tnormalized_match: 0.523\n",
      "\tnormalized_structural_match: 0.615\n",
      "\tnormalized_sari: 0.717\n",
      "\n",
      "overall scores:\n",
      "exact_match score:\tmean 0.010\tmax 1.000\tmin 0.000\n",
      "match score:\tmean 0.487\tmax 1.000\tmin 0.077\n",
      "structural_match score:\tmean 1.000\tmax 1.000\tmin 1.000\n",
      "sari score:\tmean 0.559\tmax 1.000\tmin 0.223\n",
      "ged score:\tmean 0.513\tmax 0.923\tmin 0.000\n",
      "normalized_exact_match score:\tmean 0.030\tmax 1.000\tmin 0.000\n",
      "normalized_match score:\tmean 0.455\tmax 1.000\tmin 0.108\n",
      "normalized_structural_match score:\tmean 0.528\tmax 1.000\tmin 0.000\n",
      "normalized_sari score:\tmean 0.688\tmax 1.000\tmin 0.335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# eval constrained LLM\n",
    "ngram_model = Model(\"HuggingFaceTB/SmolLM-135M\", retriever, unigram_grammar, n_few_shot=1)\n",
    "run_eval(ngram_model)\n",
    "del ngram_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38c5a5c9-c6a9-4a7d-82b6-8622863f2f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:02<00:00, 33.88it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:02<00:00, 42.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.6190476190476191, 'recall': 0.13, 'f1': 0.21487603305785125}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Baseline grammar\n",
    "baseline_grammar = ''.join(open('grammar.lark', 'r'))\n",
    "baseline_grammar_metrics = get_grammar_metrics(baseline_grammar)\n",
    "print(baseline_grammar_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d06b03c-3bd1-4511-b397-36cddcac198d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [18:15<00:00, 109.54s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:02<00:00, 46.87it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 80582.21it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:02<00:00, 36.25it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:02<00:00, 41.39it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 5470.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating example #0\n",
      "\tid: ATIS_dev_0\n",
      "\tquestion: what flights are available tomorrow from denver to philadelphia \n",
      "\tgold: return flights ;return #1 from denver ;return #2 to philadelphia ;return #3 if available\n",
      "\tprediction: return flights from denver ;return #1 from philadelphia ;return #2 to philadelphia ;return #3 that are\n",
      "\texact_match: 0\n",
      "\tmatch: 0.81\n",
      "\tstructural_match: 1.0\n",
      "\tsari: 0.819\n",
      "\tged: 0.19\n",
      "\tnormalized_exact_match: 0\n",
      "\tnormalized_match: 0.862\n",
      "\tnormalized_structural_match: 0.857\n",
      "\tnormalized_sari: 0.912\n",
      "evaluating example #1\n",
      "\tid: ATIS_dev_170\n",
      "\tquestion: what nonstop flights are available from oakland to philadelphia arriving between 5 and 6pm \n",
      "\tgold: return flights ;return #1 that are nonstop ;return #2 from oakland ;return #3 to philadelphia ;return #4 arriving between 5 and 6pm\n",
      "\tprediction: return flights from oakland ;return #1 from philadelphia ;return #2 from oakland ;return #3 from philadelphia\n",
      "\texact_match: 0\n",
      "\tmatch: 0.642\n",
      "\tstructural_match: 1.0\n",
      "\tsari: 0.426\n",
      "\tged: 0.358\n",
      "\tnormalized_exact_match: 0\n",
      "\tnormalized_match: 0.648\n",
      "\tnormalized_structural_match: 0.64\n",
      "\tnormalized_sari: 0.611\n",
      "evaluating example #2\n",
      "\tid: ATIS_dev_245\n",
      "\tquestion: i'd like information on the least expensive airfare round trip from pittsburgh to boston \n",
      "\tgold: return round trips airfares ;return #1 from pittsburghs ;return #2 to boston ;return the least expensive of #3\n",
      "\tprediction: return #1 from boston ;return #2 from pittsburgh ;return #3 from boston\n",
      "\texact_match: 0\n",
      "\tmatch: 0.488\n",
      "\tstructural_match: 1.0\n",
      "\tsari: 0.471\n",
      "\tged: 0.512\n",
      "\tnormalized_exact_match: 0\n",
      "\tnormalized_match: 0.516\n",
      "\tnormalized_structural_match: 0.609\n",
      "\tnormalized_sari: 0.637\n",
      "evaluating example #3\n",
      "\tid: ATIS_dev_319\n",
      "\tquestion: i need a flight from pittsburgh to new york city \n",
      "\tgold: return flights ;return #1 from pittsburgh ;return #2 to new york city\n",
      "\tprediction: return flights #1 from\n",
      "\texact_match: 0\n",
      "\tmatch: 0.476\n",
      "\tstructural_match: 1.0\n",
      "\tsari: 0.349\n",
      "\tged: 0.524\n",
      "\tnormalized_exact_match: 0\n",
      "\tnormalized_match: 0.308\n",
      "\tnormalized_structural_match: 0.267\n",
      "\tnormalized_sari: 0.664\n",
      "evaluating example #4\n",
      "\tid: ATIS_dev_391\n",
      "\tquestion: is there a flight between san francisco and boston with a stopover in dallas fort worth \n",
      "\tgold: return flights ;return #1 between san francisco ;return #2 and boston ;return #3 with a stopover in dallas fort worth\n",
      "\tprediction: return flight #1 between\n",
      "\texact_match: 0\n",
      "\tmatch: 0.323\n",
      "\tstructural_match: 1.0\n",
      "\tsari: 0.23\n",
      "\tged: 0.677\n",
      "\tnormalized_exact_match: 0\n",
      "\tnormalized_match: 0.346\n",
      "\tnormalized_structural_match: 0.4\n",
      "\tnormalized_sari: 0.43\n",
      "\n",
      "overall scores:\n",
      "exact_match score:\tmean 0.000\tmax 0.000\tmin 0.000\n",
      "match score:\tmean 0.369\tmax 0.810\tmin 0.041\n",
      "structural_match score:\tmean 1.000\tmax 1.000\tmin 1.000\n",
      "sari score:\tmean 0.498\tmax 0.819\tmin 0.190\n",
      "ged score:\tmean 0.631\tmax 0.959\tmin 0.190\n",
      "normalized_exact_match score:\tmean 0.000\tmax 0.000\tmin 0.000\n",
      "normalized_match score:\tmean 0.353\tmax 0.862\tmin 0.070\n",
      "normalized_structural_match score:\tmean 0.426\tmax 1.000\tmin 0.000\n",
      "normalized_sari score:\tmean 0.637\tmax 0.912\tmin 0.348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# eval constrained LLM\n",
    "baseline_model = Model(\"HuggingFaceTB/SmolLM-135M\", retriever, baseline_grammar, n_few_shot=1)\n",
    "run_eval(baseline_model)\n",
    "del baseline_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd376e7-5430-44d6-afac-378252394b11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
