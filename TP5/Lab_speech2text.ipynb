{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gumQhtC7W6K5"
      },
      "source": [
        "# Lab Speech2Text\n",
        "\n",
        "Welcome to the lab on speech recognition and natural language processing.\n",
        "\n",
        "In this lab, you will be working on a real-world problem where we aim to make a tedious and time-consuming job easier for the agents of an international company. We will guide you through the process of creating a proof of concept (POC) for an application designed to help agents create reports more efficiently.\n",
        "\n",
        "The problem we are tackling is a familiar one: **writing a report after an inspection or check-up**. We know that writing reports is not an easy task, especially when it comes to taking notes and structuring information correctly. In this context, the agents are required to send a detailed report to the company they work for, which can be a daunting and time-consuming task.\n",
        "\n",
        "Our goal in this lab is to build a POC for an application that allows the agents to **verbally report their findings**, with the application extracting the important information and **automatically generating the report**. To achieve this, we will be using machine learning techniques to understand spoken natural language and accurately extract relevant information from it.\n",
        "\n",
        "By the end of this lab, you will have gained a better understanding of machine learning, natural language processing, and how to apply them to real-world problems.\n",
        "\n",
        "Let's get started!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHQwRHnf9XxA"
      },
      "source": [
        "The first thing you have to do is to **make your own copy of the lab**.\n",
        "\n",
        "Go to `File` > `Save a copy in Drive`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4PkOf2N3ZxR"
      },
      "source": [
        "## I - Record the audio\n",
        "\n",
        "First of all we need to record some audio.\n",
        "\n",
        "We give you some chunks of code, make sure they work.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xh1bhUJE2Hle",
        "outputId": "e46d68b4-6d21-46b9-f5ed-315088bb4d99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from ffmpeg-python) (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install ffmpeg-python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJ3EVPPXyy9R"
      },
      "source": [
        "Make sure to run the following cell. It allows you to record audio files.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "923OeIuC2wAx"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "from IPython.display import HTML, Audio\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import numpy as np\n",
        "from scipy.io.wavfile import read as wav_read\n",
        "import io\n",
        "import ffmpeg\n",
        "\n",
        "AUDIO_HTML = \"\"\"\n",
        "<script>\n",
        "var my_div = document.createElement(\"DIV\");\n",
        "var my_p = document.createElement(\"P\");\n",
        "var my_btn = document.createElement(\"BUTTON\");\n",
        "var t = document.createTextNode(\"Press to start recording\");\n",
        "\n",
        "my_btn.appendChild(t);\n",
        "//my_p.appendChild(my_btn);\n",
        "my_div.appendChild(my_btn);\n",
        "document.body.appendChild(my_div);\n",
        "\n",
        "var base64data = 0;\n",
        "var reader;\n",
        "var recorder, gumStream;\n",
        "var recordButton = my_btn;\n",
        "\n",
        "var handleSuccess = function(stream) {\n",
        "  gumStream = stream;\n",
        "  var options = {\n",
        "    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n",
        "    mimeType : 'audio/webm;codecs=opus'\n",
        "    //mimeType : 'audio/webm;codecs=pcm'\n",
        "  };\n",
        "  //recorder = new MediaRecorder(stream, options);\n",
        "  recorder = new MediaRecorder(stream);\n",
        "  recorder.ondataavailable = function(e) {\n",
        "    var url = URL.createObjectURL(e.data);\n",
        "    var preview = document.createElement('audio');\n",
        "    preview.controls = true;\n",
        "    preview.src = url;\n",
        "    document.body.appendChild(preview);\n",
        "\n",
        "    reader = new FileReader();\n",
        "    reader.readAsDataURL(e.data);\n",
        "    reader.onloadend = function() {\n",
        "      base64data = reader.result;\n",
        "      //console.log(\"Inside FileReader:\" + base64data);\n",
        "    }\n",
        "  };\n",
        "  recorder.start();\n",
        "  };\n",
        "\n",
        "recordButton.innerText = \"Recording... press to stop\";\n",
        "\n",
        "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
        "\n",
        "function toggleRecording() {\n",
        "  if (recorder && recorder.state == \"recording\") {\n",
        "      recorder.stop();\n",
        "      gumStream.getAudioTracks()[0].stop();\n",
        "      recordButton.innerText = \"Saving the recording... pls wait!\"\n",
        "  }\n",
        "}\n",
        "\n",
        "function sleep(ms) {\n",
        "  return new Promise(resolve => setTimeout(resolve, ms));\n",
        "}\n",
        "\n",
        "var data = new Promise(resolve=>{\n",
        "//recordButton.addEventListener(\"click\", toggleRecording);\n",
        "recordButton.onclick = ()=>{\n",
        "toggleRecording()\n",
        "\n",
        "sleep(2000).then(() => {\n",
        "  // wait 2000ms for the data to be available...\n",
        "  // ideally this should use something like await...\n",
        "  //console.log(\"Inside data:\" + base64data)\n",
        "  resolve(base64data.toString())\n",
        "\n",
        "});\n",
        "\n",
        "}\n",
        "});\n",
        "\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def get_audio():\n",
        "    display(HTML(AUDIO_HTML))\n",
        "    data = eval_js(\"data\")\n",
        "    binary = b64decode(data.split(\",\")[1])\n",
        "\n",
        "    process = (\n",
        "        ffmpeg.input(\"pipe:0\")\n",
        "        .output(\"pipe:1\", format=\"wav\")\n",
        "        .run_async(\n",
        "            pipe_stdin=True,\n",
        "            pipe_stdout=True,\n",
        "            pipe_stderr=True,\n",
        "            quiet=True,\n",
        "            overwrite_output=True,\n",
        "        )\n",
        "    )\n",
        "    output, err = process.communicate(input=binary)\n",
        "\n",
        "    riff_chunk_size = len(output) - 8\n",
        "    # Break up the chunk size into four bytes, held in b.\n",
        "    q = riff_chunk_size\n",
        "    b = []\n",
        "    for i in range(4):\n",
        "        q, r = divmod(q, 256)\n",
        "        b.append(r)\n",
        "\n",
        "    # Replace bytes 4:8 in proc.stdout with the actual size of the RIFF chunk.\n",
        "    riff = output[:4] + bytes(b) + output[8:]\n",
        "\n",
        "    sr, audio = wav_read(io.BytesIO(riff))\n",
        "\n",
        "    return audio, sr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgNI6RwmzAxj"
      },
      "source": [
        "Now you can record yourself. Try making several examples, in different langagues, different tones etc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tGo-Euz20Jh"
      },
      "outputs": [],
      "source": [
        "import scipy\n",
        "\n",
        "\n",
        "audio, sr = get_audio()\n",
        "\n",
        "scipy.io.wavfile.write(\"recording.wav\", sr, audio)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8athubTzKEC"
      },
      "source": [
        "You can also download a full audio report with the cell below :\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rn8piRezzTP7",
        "outputId": "b4b3d7c6-70d3-47b6-f8d4-c460446698cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-03-12 07:46:24--  https://github.com/bourliam/s2t_lab/raw/main/RapportMarc.mp3\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/bourliam/s2t_lab/main/RapportMarc.mp3 [following]\n",
            "--2025-03-12 07:46:25--  https://raw.githubusercontent.com/bourliam/s2t_lab/main/RapportMarc.mp3\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2058240 (2.0M) [audio/mpeg]\n",
            "Saving to: ‘RapportMarc.mp3.1’\n",
            "\n",
            "RapportMarc.mp3.1   100%[===================>]   1.96M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2025-03-12 07:46:25 (44.2 MB/s) - ‘RapportMarc.mp3.1’ saved [2058240/2058240]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/bourliam/s2t_lab/raw/main/RapportMarc.mp3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AwJbtOS4MiE"
      },
      "source": [
        "## II - Process the audio file to get the text\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxwdE9F7zI-W"
      },
      "source": [
        "Now that we have some audio material, it is time to extract the information they contain.\n",
        "\n",
        "We will try several models and compare them.\n",
        "The key study points are :\n",
        "\n",
        "- The performance : ie how good is it working\n",
        "- The compute time : we don't want it taking too much time\n",
        "- The size : It would be great if our application could run on a smartphone\n",
        "- The price : Last but not least, the usage cost is an important parameter\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Chns4kveUa5"
      },
      "source": [
        "### 1 - Google Speech to Text\n",
        "\n",
        "The first model we want to try is from Google. Their model is available via an API but also via a library.\n",
        "\n",
        "Try installing the lib SpeechRecognition (https://github.com/Uberi/speech_recognition/tree/master) and use the method `recognize_google()`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWwN1xHVcIkT",
        "outputId": "4303db3a-4191-480e-f212-4aa03cda3066"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.11/dist-packages (3.14.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from SpeechRecognition) (4.12.2)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (0.25.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install SpeechRecognition\n",
        "!pip install pydub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-IDqFH6ryLT",
        "outputId": "d7e97f49-17cd-43a1-8702-f751369eccde"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<_io.BufferedRandom name='RapportMarc.wav'>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import speech_recognition as sr\n",
        "from pydub import AudioSegment\n",
        "\n",
        "audio = AudioSegment.from_mp3(\"RapportMarc.mp3\")\n",
        "audio.export(\"RapportMarc.wav\", format=\"wav\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXqNxVaz4O8i",
        "outputId": "a707fc6d-57a5-44f2-96cb-d796b497982c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transcription: salut c'est Marc Dupont ici juste pour te raconter un peu comment ça s'est passé chez notre client l'agence digitale innovantes à Paris tu sais celle de la rue des innovateurs alors aujourd'hui c'était la routine habituelle au début nettoyage de l'accueil des toilettes de la salle de réunion vidage des poubelles tout ça j'ai aussi fait les vitres de la salle de réunion parce qu'il y avait plein de traces de doigts dessus dans les bureaux j'ai chassé la poussière passer l'aspi partout et donner un peu d'eau aux plantes rien de bien fou ici mais alors le moment un peu galère de la journée c'était pour accéder à la salle des serveurs mon badge je sais pas pourquoi il voulait rien savoir bloqué de chez bloqué du coup j'ai dû embêter Camille Leroy tu sais la responsable a été là-bas elle a été super cool elle m'a filé son badge pour que je puisse faire mon taf dans la salle elle m'a dit qu'ils allaient checker les badges de notre team pour qu'on se retrouve pas dans la même galère à l'avenir Camille elle a été clair sur le fait que c'est hyper important de garder cette salle nickel pour que tout roule bien pour eux elle a dit qu'elle s'occupe de faire le suivi avec la sécu pour mettre nos badges à jour alors si tu as le même souci tu sais pour rentrer dans la salle des serveurs Camille et celle à qui parler tu peux la joindre au 01 55 55 55 55 ou lui envoyer un mail à Camille Leroy agence digitale innovante fr voilà c'est tout pour le rapport du jour je vais garder un œil sur cette histoire de badge pour être sûr que ça se règle vite voilà ciao Marc Dupont\n"
          ]
        }
      ],
      "source": [
        "recognizer = sr.Recognizer()\n",
        "\n",
        "with sr.AudioFile(\"RapportMarc.wav\") as source:\n",
        "    audio_data = recognizer.record(source)  # Record the entire file\n",
        "    result_google = recognizer.recognize_google(audio_data, language=\"fr\")\n",
        "    print(\"Transcription:\", result_google)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcdMIk24Qpj5"
      },
      "source": [
        "### 2 - Whisper tiny\n",
        "\n",
        "There are several versions of whisper with different sizes. Try the tiny version available on Hugging Face.\n",
        "\n",
        "https://huggingface.co/openai/whisper-tiny\n",
        "\n",
        "Use the [inference API](https://huggingface.co/docs/api-inference/tasks/automatic-speech-recognition), do not try loading the model here in colab.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlzCGrl-s529",
        "outputId": "94103c24-f8a4-4647-f38f-2083125ee3b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: huggingface_hub==0.29.2 in /usr/local/lib/python3.11/dist-packages (0.29.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.29.2) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.29.2) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.29.2) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.29.2) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.29.2) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.29.2) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.29.2) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub==0.29.2) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub==0.29.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub==0.29.2) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub==0.29.2) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "!pip install huggingface_hub==0.29.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64mI9ofBQpGI",
        "outputId": "3d7209f8-6f29-4071-8210-806819be2863"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transcription:  Salut, c'est Marc du pont ici. Juste pour te raconter un peu comment ça s'est passé chez notre client la chance digital inovente à Paris, tu sais, celle de la rue des innovateurs. Alors aujourd'hui, c'était la routine habituée à l'audébut, nettoyage de la kei, détoylette, de la salle de réunion, vidages des poubelles, tout ça. J'ai aussi fait les vitres de la salle de réunion parce qu'il y avait plein de traces de doigts dessus. Dans les bureaux, j'ai chassé la poussière, passé la spipe partout et donner un peu d'eau ou plante. Rienne bien fou ici. Mais alors, le moment un peu galère de la journée c'était pour accéder à la salle des serveurs. Mon bâde je sais pas pourquoi il voulait rien savoir bloquer de chez bloquer. Du coup, j'ai dû embêter Camille le roi, tu sais, la responsable IT-Laba. Elle a été super cool, elle m'a filé son bâde pour que je puisse faire mon tâfe dans la salle. Elle m'a dit qu'ils allait checker les bâches de notre team pour qu'on se retrouve pas dans la même galère à l'avenir. Camille a été clair sur le fait que c'est hyper important de garder cette salle nickel pour que tout roule bien pour eux. Elle a dit qu'elle s'occupe de faire le suivi avec la sécu pour mettre nos bâches à jour. Alors si t'as le même souci, tu sais pour rentrer dans la salle des serveurs, camis et celles à qui parler. Tu peux la joindre aux 0,555,5555 ou lui envoyer un mail à camis du roi agence digitale inovente.fr. Voilà c'est tout pour le rapport du jour. Je vais garder un œil sur cette histoire de badge pour être sûr que ça serait le vite. Voilà, ciao, Marc du pont.\n"
          ]
        }
      ],
      "source": [
        "from huggingface_hub import InferenceClient\n",
        "\n",
        "HF_TOKEN = \"\"\n",
        "model = \"openai/whisper-tiny\"\n",
        "client = InferenceClient(token=HF_TOKEN)\n",
        "\n",
        "with open(\"RapportMarc.wav\", \"rb\") as f:\n",
        "    audio_data = f.read()\n",
        "\n",
        "result_whisper_tiny = client.automatic_speech_recognition(\n",
        "    audio=audio_data,\n",
        "    model=model,\n",
        "    extra_body={\"return_timestamps\": True, \"generate_kwargs\": {\"language\": \"fr\"}},\n",
        ").text\n",
        "\n",
        "print(\"Transcription:\", result_whisper_tiny)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdRD47ZM84tQ"
      },
      "source": [
        "### 3 - OpenAI Whisper v3 From Hugging Face\n",
        "\n",
        "OpenAI actually released a new version of whisper available on Hugging Face.\n",
        "\n",
        "Model page : https://huggingface.co/openai/whisper-large-v3\n",
        "\n",
        "Use the [inference API](https://huggingface.co/docs/api-inference/tasks/automatic-speech-recognition), do not try loading the model here in colab.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3CbgwI96-84",
        "outputId": "3fe74b03-46a5-4b66-ef1c-e987822a0733"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transcription:  Salut, c'est Marc Dupont ici. Juste pour te raconter un peu comment ça s'est passé chez notre client, l'agence digitale innovante à Paris, tu sais, celle de la rue des innovateurs. Alors aujourd'hui, c'était la routine habituelle au début. Nettoyage de l'accueil, des toilettes, de la salle de réunion, vidage des poubelles, tout ça. J'ai aussi fait les vitres de la salle de réunion, parce qu'il y avait plein de traces de doigts dessus. dans les bureaux j'ai chassé la poussière passé la spie partout et donné un peu d'eau aux plantes rien de bien fou ici mais alors le moment un peu galère de la journée c'était pour accéder à la salle des serveurs mon badge je sais pas pourquoi il voulait rien savoir bloqué de chez bloqué du coup j'ai dû embêter Camille Leroy tu sais la responsable IT là-bas elle a été super cool elle m'a filé son badge pour que je puisse faire mon taf dans la salle Elle m'a dit qu'ils allaient checker les badges de notre team pour qu'on ne se retrouve pas dans la même galère à l'avenir. Camille, elle a été claire sur le fait que c'est hyper important de garder cette salle nickel pour que tout roule bien pour eux. Elle a dit qu'elle s'occupe de faire le suivi avec la sécu pour mettre nos badges à jour. Alors si t'as le même souci, tu sais, pour entrer dans la salle des serveurs, Camille est celle à qui parler. Tu peux la joindre au 01 55 555 5555 ou lui envoyer un mail à camidleroyagencedigitalinnovante.fr Voilà, c'est tout pour le rapport du jour. Je vais garder un œil sur cette histoire de badge pour être sûr que ça se règle vite. Voilà, ciao, Marc Dupont.\n"
          ]
        }
      ],
      "source": [
        "model = \"openai/whisper-large-v3\"\n",
        "client = InferenceClient(token=HF_TOKEN)\n",
        "\n",
        "with open(\"RapportMarc.wav\", \"rb\") as f:\n",
        "    audio_data = f.read()\n",
        "\n",
        "result_whisper_large = client.automatic_speech_recognition(\n",
        "    audio=audio_data, model=model, extra_body={\"generate_kwargs\": {\"language\": \"fr\"}}\n",
        ").text\n",
        "\n",
        "print(\"Transcription:\", result_whisper_large)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qOQXbPW4e5y"
      },
      "source": [
        "### 4 - Results\n",
        "\n",
        "Write here your findings, which model you plan to use and why.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iYE9yTB4qfB"
      },
      "source": [
        "---\n",
        "Answer here\n",
        "---\n",
        "\n",
        "Looking at the three transcriptions, we can see that the best one is the one from Whisper large v3. It is the most accurate and the most complete.\n",
        "\n",
        "Hence, we will use this model for the rest of the lab.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZrhIaYPiAJJ"
      },
      "source": [
        "## III - Generate a full report\n",
        "\n",
        "Now that you have extracted the text and all the informations, you have to generate a report.\n",
        "\n",
        "You can use models available on the [Hugging Face Hub](https://huggingface.co/docs/api-inference/tasks/chat-completion).\n",
        "\n",
        "Tips : As you want the report to be well formatted you will have find how to prompt the model to achieve this goal.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_dL96Xu-18y"
      },
      "source": [
        "Some key elements we want to extract :\n",
        "\n",
        "- The agent's name\n",
        "- The client's name\n",
        "- The client's adress\n",
        "- What was done\n",
        "- What problems there were\n",
        "- ...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPtdl91U_M4-",
        "outputId": "52d99e9f-f111-414f-f068-af8ad19f5a5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.29.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfOS6S925IUt",
        "outputId": "f5f6d249-5a7e-4132-abd4-047f33ce7602"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "```json\n",
            "{\n",
            "  \"agent's_name\": \"Marc Dupont\",\n",
            "  \"client's_name\": \"Agence digitale innovante\",\n",
            "  \"client's_address\": \"rue des innovateurs, Paris\",\n",
            "  \"what_was_done\": \"Cleaning (reception, toilets, meeting room, waste disposal), window cleaning, dusting, watering plants\",\n",
            "  \"problems_there_were\": \"Access issue to server room due to badge malfunction, scheduled follow-up needed with security for updated badges\",\n",
            "  \"contact_informations\": \"01 55 555 5555 (phone), camidleroyagencedigitalinnovante.fr (email)\"\n",
            "}\n",
            "```"
          ]
        }
      ],
      "source": [
        "client = InferenceClient(provider=\"hf-inference\", api_key=HF_TOKEN)\n",
        "\n",
        "informations = \", \".join(\n",
        "    [\n",
        "        \"agent's name\",\n",
        "        \"client's name\",\n",
        "        \"client's address\",\n",
        "        \"what was done\",\n",
        "        \"what problems there were\",\n",
        "        \"contact informations\",\n",
        "    ]\n",
        ")\n",
        "\n",
        "prompt_template = \"\"\"Extract these informations:\n",
        "\\t{informations}\n",
        "from the following text:\n",
        "\\t{text}.\n",
        "Don't add informations you don't find in the text.\n",
        "Return the extracted informations in JSON format.\"\"\"\n",
        "prompt = prompt_template.format(\n",
        "    informations=informations, text=result_whisper_large.strip()\n",
        ")\n",
        "\n",
        "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "\n",
        "stream = client.chat.completions.create(\n",
        "    model=\"google/gemma-2-2b-it\", messages=messages, max_tokens=500, stream=True\n",
        ")\n",
        "\n",
        "for chunk in stream:\n",
        "    print(chunk.choices[0].delta.content, end=\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKrs3xoOU0sf"
      },
      "source": [
        "As we can see, the report is quite structured. This indicates that both out speech to text and our text to text models are able to understand the context of the conversation.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
