{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfb45e4-daa5-4616-84b0-6f129ebe79fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell A\n",
    "# dowload data: fragment of the Penn treebank\n",
    "import nltk\n",
    "from nltk.corpus import treebank\n",
    "import nltk.tree.tree as ntree\n",
    "nltk.download('treebank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796524b2-2fae-4e7a-b926-815522ddc80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell B\n",
    "def depth_first_traversal(tree):\n",
    "    if isinstance(tree, ntree.Tree):\n",
    "        label='{}'.format(tree.label())\n",
    "        output = [label]\n",
    "        for child_traversal, isterminal in [depth_first_traversal(t) for t in tree]:\n",
    "            if isterminal:\n",
    "                output.append(child_traversal)\n",
    "            else:\n",
    "                output.extend(child_traversal)\n",
    "        return (output + ['REDUCE'], False)\n",
    "    else:\n",
    "        assert isinstance(tree, str)\n",
    "        return 'SHIFT', True\n",
    "        \n",
    "data = [] # items\n",
    "for fileid in treebank.fileids():\n",
    "    gold_trees = treebank.parsed_sents(fileid)\n",
    "    for tree in gold_trees:\n",
    "        sentence = list(tree.leaves())\n",
    "        action_sequence, _ = depth_first_traversal(tree)\n",
    "        num_shifts = len(list(filter(lambda x: x=='SHIFT', action_sequence)))\n",
    "        assert num_shifts == len(sentence), '{}: {}'.format(fileid, sentence)\n",
    "        data.append((sentence, action_sequence, tree))\n",
    "\n",
    "# split train-dev-test\n",
    "import random\n",
    "import math\n",
    "random.seed(0)\n",
    "data.sort()\n",
    "random.shuffle(data)\n",
    "def split(list, fraction):\n",
    "    index = int(math.ceil(len(list)*fraction))\n",
    "    return list[:index], list[index:]\n",
    "#train, dev, test = data[:100], data[100:200], data[200:300]\n",
    "test, train = split(data, .1) # 10% training data\n",
    "dev, train = split(train, .1) # 10% of train is for dev\n",
    "data = {'train': train, 'dev': dev, 'test': test}\n",
    "action_lengths = sorted([len(x[1]) for x in train])\n",
    "MAX_STEPS = action_lengths[int(.9*len(action_lengths))]\n",
    "for split, d in data.items():\n",
    "    print('{}: {} samples'.format(split, len(d)))\n",
    "print('max parser steps at inference time: {}'.format(MAX_STEPS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204952a4-b819-4c60-8ea9-d34aee8bd6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell C\n",
    "# shift-reduce parser\n",
    "class ShiftReduceParser:\n",
    "    def __init__(self, reduce='REDUCE', shift='SHIFT', no_op='NOOP'):\n",
    "        self.reduce_kw = reduce\n",
    "        self.shift_kw = shift\n",
    "        self.noop_kw = no_op # this is used to do nothing, for padding\n",
    "\n",
    "    def reset(self):\n",
    "        self.buffer = []\n",
    "        self.stack = []\n",
    "\n",
    "    def initialize_with_sentence(self, sentence):\n",
    "        assert isinstance(sentence, list)\n",
    "        self.reset()\n",
    "        self.buffer = sentence[::-1]\n",
    "        assert len(self.stack) == 0\n",
    "    \n",
    "    def shift(self):\n",
    "        if len(self.buffer) == 0:\n",
    "            return\n",
    "        word = self.buffer.pop()\n",
    "        self.stack.append((word,True))\n",
    "\n",
    "    def print_state(self):\n",
    "        stack_str = 'STACK: {}'.format(self.stack)\n",
    "        buffer_str = 'BUFFER: {}'.format(self.buffer)\n",
    "        return '\\n'.join([stack_str, buffer_str])\n",
    "\n",
    "    def reduce(self):\n",
    "        # pop stack until an uncompleted nonterminal is encountered\n",
    "        completed_items = []\n",
    "        head = None\n",
    "        while True:\n",
    "            if not self.stack:\n",
    "                break\n",
    "            item = self.stack.pop()\n",
    "            if not item[1]: # item is uncompleted\n",
    "                head = item # so this will be the head in the reduce operation\n",
    "                break\n",
    "            completed_items.append(item)\n",
    "        # end while True:\n",
    "        if head is None:\n",
    "            # put stuff back on the stack! otherwise calling reduce twice could delete items from the stack\n",
    "            self.stack.extend(completed_items[::-1])\n",
    "            return\n",
    "        new_tree = ntree.Tree(head[0], [x[0] for x in completed_items[::-1]])\n",
    "        self.stack.append((new_tree, True))\n",
    "\n",
    "    def nonterminal(self, nont):\n",
    "        # put open non-terminal on stack\n",
    "        self.stack.append((nont, False))\n",
    "\n",
    "    def return_parse(self, force=False):\n",
    "        if not force:\n",
    "            assert self.done()\n",
    "            return self.stack[0][0]\n",
    "        assert force\n",
    "        # force cast to a tree\n",
    "        if len(self.stack) == 0:\n",
    "            candidate_tree = 'S'\n",
    "        else:\n",
    "            candidate_tree = self.stack[-1][0]\n",
    "            candidate_trees = list(filter(lambda x: isinstance(x[0], ntree.Tree), self.stack))\n",
    "            if len(candidate_trees)>0:\n",
    "                candidate_tree = sorted(candidate_trees, key=lambda x: x[0].height())[-1][0]\n",
    "        assert isinstance(candidate_tree, ntree.Tree) or isinstance(candidate_tree, str), candidate_tree\n",
    "        if not isinstance(candidate_tree, ntree.Tree):\n",
    "            candidate_tree = ntree.Tree(candidate_tree, [])\n",
    "        return candidate_tree\n",
    "\n",
    "    def step(self, action):\n",
    "        if action == self.reduce_kw:\n",
    "            self.reduce()\n",
    "        elif action == self.shift_kw:\n",
    "            self.shift()\n",
    "        elif action == self.noop_kw:\n",
    "            pass\n",
    "        else:\n",
    "            self.nonterminal(action)\n",
    "            \n",
    "    def done(self):\n",
    "        buffer_empty = len(self.buffer) == 0\n",
    "        single_item = (len(self.stack) == 1)\n",
    "        completed = False\n",
    "        if single_item:\n",
    "            completed = self.stack[0][1]\n",
    "        return buffer_empty and single_item and completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de2ba2f-a525-46e4-a65a-1e70f284b378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell D\n",
    "# check validity of parser\n",
    "test_parser = ShiftReduceParser()\n",
    "for split, d in data.items():\n",
    "    for sentence, actions, tree in d:\n",
    "        test_parser = ShiftReduceParser()\n",
    "        test_parser.initialize_with_sentence(sentence)\n",
    "        for action in actions:\n",
    "            test_parser.step(action)\n",
    "        assert test_parser.done()\n",
    "        assert test_parser.return_parse() == tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc470a0d-5c41-4bbd-a6a6-fc51a4b5949b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell E\n",
    "# trainer class\n",
    "# Q1: What do the \"dependency\" metrics measure?\n",
    "# Q1: You do not need to explain what precision, recall and F1 are,\n",
    "# Q1: but you do need to explain what sets they are computed against.\n",
    "\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "\n",
    "class Metrics:\n",
    "    def __init__(self):\n",
    "        self.exact_match = None\n",
    "        self.edit_distance = None\n",
    "        self.precision = None\n",
    "        self.recall = None\n",
    "        self.f1 = None\n",
    "\n",
    "    def reset(self):\n",
    "        self.exact_match = []\n",
    "        self.edit_distance = []\n",
    "        self.subtree_precision = []\n",
    "        self.subtree_recall = []\n",
    "        self.subtree_f1 = []\n",
    "        self.dependency_precision = []\n",
    "        self.dependency_recall = []\n",
    "        self.dependency_f1 = []\n",
    "\n",
    "    def overlap(self, forest1, forest2):\n",
    "        counter = 0\n",
    "        # candidate in forest1 can only match once\n",
    "        for t1 in forest1:\n",
    "            for t2 in forest2:\n",
    "                if t1==t2:\n",
    "                    counter += 1\n",
    "                    break\n",
    "        return counter\n",
    "        \n",
    "    def levenshtein_distance(self, a, b):\n",
    "        output = {}\n",
    "        assert isinstance(a, list)\n",
    "        assert isinstance(b, list)\n",
    "        for ii in range(1+len(a)):\n",
    "            output[(ii,0)] = ii\n",
    "            for jj in range(1+len(b)):\n",
    "                output[(0, jj)] = jj\n",
    "                if ii and jj:\n",
    "                    output[(ii,jj)] = min(\n",
    "                        output[(ii-1,jj)] + 1,\n",
    "                        output[(ii, jj-1)] + 1,\n",
    "                        output[(ii-1, jj-1)] + int(a[ii-1]!=b[jj-1]))\n",
    "        return output[(len(a),len(b))]\n",
    "    \n",
    "    def record_sequences(self, predictions, gold_sequences):\n",
    "        assert len(predictions) == len(gold_sequences)\n",
    "        def is_list_of_list_of_str(x):\n",
    "            output = isinstance(x, list)\n",
    "            for y in x:\n",
    "                output &= isinstance(y, list)\n",
    "                for z in y:\n",
    "                    output &= isinstance(z, str)\n",
    "            return output\n",
    "        assert is_list_of_list_of_str(gold_sequences), gold_sequences\n",
    "        assert is_list_of_list_of_str(predictions), predictions\n",
    "        for p, g in zip(predictions, gold_sequences):\n",
    "            self.edit_distance.append(self.levenshtein_distance(p,g)/len(g)) \n",
    "\n",
    "    def all_links(self, tree):\n",
    "        assert isinstance(tree, str) or isinstance(tree, ntree.Tree)\n",
    "        if isinstance(tree, str):\n",
    "            return []\n",
    "        elif len(tree) == 0:\n",
    "            return []\n",
    "        else:\n",
    "            output = [(tree.label(), child if isinstance(child, str) else child.label()) for child in tree]\n",
    "            for child in tree:\n",
    "                output.extend(self.all_links(child))\n",
    "            return output\n",
    "    \n",
    "    def record_trees(self, predictions, gold_references):\n",
    "        assert len(predictions) == len(gold_references)\n",
    "        assert all(isinstance(g, ntree.Tree) for g in gold_references)\n",
    "        assert all(isinstance(p, ntree.Tree) for p in predictions), predictions\n",
    "        for p, g in zip(predictions, gold_references):\n",
    "            self.exact_match.append(int(p==g))\n",
    "            # dependencies\n",
    "            ps = self.all_links(p)\n",
    "            gs = self.all_links(g)\n",
    "            assert gs\n",
    "            ncp = self.overlap(ps, gs) # number correct precision\n",
    "            ncr = self.overlap(gs, ps) # number correct recall\n",
    "            lps = max(1,len(ps))\n",
    "            lgs = max(1,len(gs))\n",
    "            self.dependency_precision.append(ncp/lps)\n",
    "            self.dependency_recall.append(ncr/lgs)\n",
    "            f1 = 0\n",
    "            if ncr or ncp:\n",
    "                f1 = 2*ncp*ncr/(lps*ncr + lgs*ncp)\n",
    "            self.dependency_f1.append(f1)\n",
    "            # subtrees\n",
    "            ps = list(p.subtrees())\n",
    "            gs = list(g.subtrees())\n",
    "            assert ps\n",
    "            assert gs\n",
    "            ncp = self.overlap(ps, gs) # number correct precision\n",
    "            ncr = self.overlap(gs, ps) # number correct recall\n",
    "            lps = max(1,len(ps))\n",
    "            lgs = max(1,len(gs))\n",
    "            self.subtree_precision.append(ncp/lps)\n",
    "            self.subtree_recall.append(ncr/lgs)\n",
    "            f1 = 0\n",
    "            if ncr or ncp:\n",
    "                f1 = 2*ncp*ncr/(lps*ncr + lgs*ncp)\n",
    "            self.subtree_f1.append(f1)\n",
    "\n",
    "    def get_metrics(self):\n",
    "        def mean(l):\n",
    "            return sum(l)/len(l)\n",
    "        output = {'exact match': mean(self.exact_match),\n",
    "                  'dependency precision': mean(self.dependency_precision),\n",
    "                  'dependency recall': mean(self.dependency_recall),\n",
    "                  'dependency f1': mean(self.dependency_f1),\n",
    "                  'subtree precision': mean(self.subtree_precision),\n",
    "                  'subtree recall': mean(self.subtree_recall),\n",
    "                  'subtree f1': mean(self.subtree_f1),\n",
    "                  'edit distance': mean(self.edit_distance),\n",
    "                  'N': {\n",
    "                      'exact match': len(self.exact_match),\n",
    "                      'dependency precision': len(self.dependency_precision),\n",
    "                      'dependency recall': len(self.dependency_recall),\n",
    "                      'dependency f1': len(self.dependency_f1),\n",
    "                      'subtree precision': len(self.subtree_precision),\n",
    "                      'subtree recall': len(self.subtree_recall),\n",
    "                      'subtree f1': len(self.subtree_f1),\n",
    "                      'edit distance': len(self.edit_distance),\n",
    "                      }\n",
    "                  }\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f8ead5-3a39-4b82-aa77-3deac827a522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell F\n",
    "# BM25 retriever\n",
    "# Q2: What is BM25? How does this retriever work?\n",
    "from rank_bm25 import BM25Okapi\n",
    "class FewShotRetriever:\n",
    "    def __init__(self, data_set):\n",
    "        # data_set contains items from the training set\n",
    "        assert isinstance(data_set, list)\n",
    "        assert all(isinstance(x, tuple) for x in data_set)\n",
    "        self.data = [(x[0], x[1]) for x in data_set]\n",
    "        self.bm25 = None\n",
    "    def build_index(self):\n",
    "        self.corpus = [x[0] for x in self.data]\n",
    "        self.bm25 = BM25Okapi(self.corpus)\n",
    "    def get_samples(self, query, n=4):\n",
    "        tokenized_query = query.split(\" \")\n",
    "        top_n = self.bm25.get_top_n(tokenized_query, self.data, n=n)\n",
    "        return top_n\n",
    "\n",
    "# build retriever on training data\n",
    "retriever = FewShotRetriever(data['train'])\n",
    "retriever.build_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61d6167-5e8b-499e-8348-d3e7bd02c2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell G\n",
    "import numpy as np\n",
    "import scipy.stats as sh\n",
    "def valid_estimate(records):\n",
    "    assert isinstance(records, list)\n",
    "    assert len(records)>0\n",
    "    assert all(isinstance(x, float) for x in records)\n",
    "    mu = np.mean(records)\n",
    "    interval = sh.t.interval(confidence=.9, df=len(records)-1, loc=mu, scale=sh.sem(records))\n",
    "    criterion = (interval[1]-interval[0]) < .1\n",
    "    return criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c242ba-843b-4a40-b53a-5eecc5df418a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell H\n",
    "# LLM parser\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "import json\n",
    "class LLMParser:\n",
    "    def __init__(self, model_name, retriever, n_few_shot=2, max_tokens=100):\n",
    "        assert isinstance(retriever, FewShotRetriever)\n",
    "        self.retriever=retriever\n",
    "        assert isinstance(max_tokens, int)\n",
    "        self.max_tokens = max_tokens\n",
    "        assert isinstance(model_name, str)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(model_name, pad_token_id=self.tokenizer.eos_token_id)\n",
    "        assert isinstance(n_few_shot, int)\n",
    "        self.n_few_shot=n_few_shot\n",
    "\n",
    "    def generate(self, input_strings):\n",
    "        assert isinstance(input_strings, list)\n",
    "        assert len(input_strings)>0\n",
    "        assert all(isinstance(ii, str) for ii in input_strings)\n",
    "        prompts = self.make_prompts(input_strings)\n",
    "        pipe = pipeline(\n",
    "            \"text-generation\", \n",
    "            model=self.model,\n",
    "            tokenizer=self.tokenizer\n",
    "        )\n",
    "        generation_args = {\n",
    "            \"max_new_tokens\": self.max_tokens,\n",
    "            \"return_full_text\": False,\n",
    "            \"do_sample\": False,\n",
    "            \"stop_strings\": ['\\n'],\n",
    "            \"tokenizer\": self.tokenizer,\n",
    "            \"pad_token_id\": self.tokenizer.eos_token_id\n",
    "\n",
    "        }\n",
    "        output = pipe(prompts, **generation_args)\n",
    "        output = [oo[0] for oo in output]\n",
    "        assert len(output) == len(prompts)\n",
    "        output = [{'prompt': prompt, 'lm_output': x['generated_text']} for x, prompt in zip(output, prompts)]\n",
    "        return output\n",
    "    \n",
    "    def make_prompt(self, input_string):\n",
    "        samples = self.retriever.get_samples(input_string, n=self.n_few_shot)\n",
    "        #assert len(samples) == self.n_few_shot\n",
    "        prompt = [\"{}\\n{}\".format(\" \".join(x), \" \".join(y)) for x, y in samples]\n",
    "        prompt.append(\"{}\\n\".format(input_string))\n",
    "        prompt = '\\n'.join(prompt)\n",
    "        return prompt\n",
    "        \n",
    "    def make_prompts(self, input_strings):\n",
    "        prompts = [self.make_prompt(input_string) for input_string in input_strings]\n",
    "        return prompts\n",
    "\n",
    "    def eval(self, data, batch_size=16, variable_size=False):\n",
    "        if variable_size:\n",
    "            return self.eval_variable_size(data, batch_size=batch_size)\n",
    "        metrics = Metrics()\n",
    "        metrics.reset()\n",
    "        for position in tqdm(range(0,len(data),batch_size)):\n",
    "            chunk = data[position:position+batch_size]\n",
    "            assert len(chunk)>0\n",
    "            # chunk is a list of tuples (input_seq, action_seq, tree)\n",
    "            self.eval_step(chunk, metrics)\n",
    "        return metrics.get_metrics()\n",
    "\n",
    "    def eval_variable_size(self, data, batch_size=16):\n",
    "        metrics = Metrics()\n",
    "        metrics.reset()\n",
    "        position=0\n",
    "        terminate=False\n",
    "        while (position<len(data)) and (not terminate):\n",
    "            chunk = data[position:position+batch_size]\n",
    "            assert len(chunk)>0\n",
    "            # chunk is a list of tuples (input_seq, action_seq, tree)\n",
    "            self.eval_step(chunk, metrics)\n",
    "            position+=batch_size\n",
    "            terminate = valid_estimate(metrics.edit_distance)\n",
    "        return metrics.get_metrics()\n",
    "\n",
    "    def eval_step(self, chunk, metrics):\n",
    "        # chunk is a list of tuples (input_seq, action_seq, tree)\n",
    "        sentences = [\" \".join(x[0]) for x in chunk] # this is a very basic form of detokenization\n",
    "        y = self.generate(sentences)\n",
    "        generated_sequences = [x['lm_output'].split() for x in y]\n",
    "        metrics.record_sequences(generated_sequences, [x[1] for x in chunk])\n",
    "        trees = []\n",
    "        for ii,sentence in enumerate(sentences):\n",
    "            parser=ShiftReduceParser()\n",
    "            parser.initialize_with_sentence(sentence.split())\n",
    "            for action in generated_sequences[ii]:\n",
    "                parser.step(action)\n",
    "            trees.append(parser.return_parse(force=True))\n",
    "        assert len(trees) == len(chunk)\n",
    "        metrics.record_trees(trees, [x[2] for x in chunk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22357cda-b2a0-409c-a1a9-dc37314dbef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell I\n",
    "llm_parser = LLMParser(\"HuggingFaceTB/SmolLM-135M\", retriever)\n",
    "# TODO report 90% confidence interval. See function \"valid_estimate\" in cell G\n",
    "for n_few_shot in [0, 1, 2, 4, 8, 16]:\n",
    "    print('=== {} ==='.format(n_few_shot))\n",
    "    llm_parser.n_few_shot=n_few_shot\n",
    "    metrics = llm_parser.eval(data['dev'], variable_size=True)\n",
    "    print(json.dumps(metrics, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
