{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccfb45e4-daa5-4616-84b0-6f129ebe79fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     /home/ids/glorenzo-23/nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell A\n",
    "# dowload data: fragment of the Penn treebank\n",
    "import nltk\n",
    "from nltk.corpus import treebank\n",
    "import nltk.tree.tree as ntree\n",
    "import torch\n",
    "\n",
    "nltk.download(\"treebank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "796524b2-2fae-4e7a-b926-815522ddc80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 3169 samples\n",
      "dev: 353 samples\n",
      "test: 392 samples\n",
      "max parser steps at inference time: 189\n"
     ]
    }
   ],
   "source": [
    "# Cell B\n",
    "def depth_first_traversal(tree):\n",
    "    if isinstance(tree, ntree.Tree):\n",
    "        label = \"{}\".format(tree.label())\n",
    "        output = [label]\n",
    "        for child_traversal, isterminal in [depth_first_traversal(t) for t in tree]:\n",
    "            if isterminal:\n",
    "                output.append(child_traversal)\n",
    "            else:\n",
    "                output.extend(child_traversal)\n",
    "        return (output + [\"REDUCE\"], False)\n",
    "    else:\n",
    "        assert isinstance(tree, str)\n",
    "        return \"SHIFT\", True\n",
    "\n",
    "\n",
    "data = []  # items\n",
    "for fileid in treebank.fileids():\n",
    "    gold_trees = treebank.parsed_sents(fileid)\n",
    "    for tree in gold_trees:\n",
    "        sentence = list(tree.leaves())\n",
    "        action_sequence, _ = depth_first_traversal(tree)\n",
    "        num_shifts = len(list(filter(lambda x: x == \"SHIFT\", action_sequence)))\n",
    "        assert num_shifts == len(sentence), \"{}: {}\".format(fileid, sentence)\n",
    "        data.append((sentence, action_sequence, tree))\n",
    "\n",
    "# split train-dev-test\n",
    "import random\n",
    "import math\n",
    "\n",
    "random.seed(0)\n",
    "data.sort()\n",
    "random.shuffle(data)\n",
    "\n",
    "\n",
    "def split(list, fraction):\n",
    "    index = int(math.ceil(len(list) * fraction))\n",
    "    return list[:index], list[index:]\n",
    "\n",
    "\n",
    "# train, dev, test = data[:100], data[100:200], data[200:300]\n",
    "test, train = split(data, 0.1)  # 10% training data\n",
    "dev, train = split(train, 0.1)  # 10% of train is for dev\n",
    "data = {\"train\": train, \"dev\": dev, \"test\": test}\n",
    "action_lengths = sorted([len(x[1]) for x in train])\n",
    "MAX_STEPS = action_lengths[int(0.9 * len(action_lengths))]\n",
    "for split, d in data.items():\n",
    "    print(\"{}: {} samples\".format(split, len(d)))\n",
    "print(\"max parser steps at inference time: {}\".format(MAX_STEPS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "204952a4-b819-4c60-8ea9-d34aee8bd6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell C\n",
    "# shift-reduce parser\n",
    "class ShiftReduceParser:\n",
    "    def __init__(self, reduce=\"REDUCE\", shift=\"SHIFT\", no_op=\"NOOP\"):\n",
    "        self.reduce_kw = reduce\n",
    "        self.shift_kw = shift\n",
    "        self.noop_kw = no_op  # this is used to do nothing, for padding\n",
    "\n",
    "    def reset(self):\n",
    "        self.buffer = []\n",
    "        self.stack = []\n",
    "\n",
    "    def initialize_with_sentence(self, sentence):\n",
    "        assert isinstance(sentence, list)\n",
    "        self.reset()\n",
    "        self.buffer = sentence[::-1]\n",
    "        assert len(self.stack) == 0\n",
    "\n",
    "    def shift(self):\n",
    "        if len(self.buffer) == 0:\n",
    "            return\n",
    "        word = self.buffer.pop()\n",
    "        self.stack.append((word, True))\n",
    "\n",
    "    def print_state(self):\n",
    "        stack_str = \"STACK: {}\".format(self.stack)\n",
    "        buffer_str = \"BUFFER: {}\".format(self.buffer)\n",
    "        return \"\\n\".join([stack_str, buffer_str])\n",
    "\n",
    "    def reduce(self):\n",
    "        # pop stack until an uncompleted nonterminal is encountered\n",
    "        completed_items = []\n",
    "        head = None\n",
    "        while True:\n",
    "            if not self.stack:\n",
    "                break\n",
    "            item = self.stack.pop()\n",
    "            if not item[1]:  # item is uncompleted\n",
    "                head = item  # so this will be the head in the reduce operation\n",
    "                break\n",
    "            completed_items.append(item)\n",
    "        # end while True:\n",
    "        if head is None:\n",
    "            # put stuff back on the stack! otherwise calling reduce twice could delete items from the stack\n",
    "            self.stack.extend(completed_items[::-1])\n",
    "            return\n",
    "        new_tree = ntree.Tree(head[0], [x[0] for x in completed_items[::-1]])\n",
    "        self.stack.append((new_tree, True))\n",
    "\n",
    "    def nonterminal(self, nont):\n",
    "        # put open non-terminal on stack\n",
    "        self.stack.append((nont, False))\n",
    "\n",
    "    def return_parse(self, force=False):\n",
    "        if not force:\n",
    "            assert self.done()\n",
    "            return self.stack[0][0]\n",
    "        assert force\n",
    "        # force cast to a tree\n",
    "        if len(self.stack) == 0:\n",
    "            candidate_tree = \"S\"\n",
    "        else:\n",
    "            candidate_tree = self.stack[-1][0]\n",
    "            candidate_trees = list(\n",
    "                filter(lambda x: isinstance(x[0], ntree.Tree), self.stack)\n",
    "            )\n",
    "            if len(candidate_trees) > 0:\n",
    "                candidate_tree = sorted(candidate_trees, key=lambda x: x[0].height())[\n",
    "                    -1\n",
    "                ][0]\n",
    "        assert isinstance(candidate_tree, ntree.Tree) or isinstance(\n",
    "            candidate_tree, str\n",
    "        ), candidate_tree\n",
    "        if not isinstance(candidate_tree, ntree.Tree):\n",
    "            candidate_tree = ntree.Tree(candidate_tree, [])\n",
    "        return candidate_tree\n",
    "\n",
    "    def step(self, action):\n",
    "        if action == self.reduce_kw:\n",
    "            self.reduce()\n",
    "        elif action == self.shift_kw:\n",
    "            self.shift()\n",
    "        elif action == self.noop_kw:\n",
    "            pass\n",
    "        else:\n",
    "            self.nonterminal(action)\n",
    "\n",
    "    def done(self):\n",
    "        buffer_empty = len(self.buffer) == 0\n",
    "        single_item = len(self.stack) == 1\n",
    "        completed = False\n",
    "        if single_item:\n",
    "            completed = self.stack[0][1]\n",
    "        return buffer_empty and single_item and completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4de2ba2f-a525-46e4-a65a-1e70f284b378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell D\n",
    "# check validity of parser\n",
    "test_parser = ShiftReduceParser()\n",
    "for split, d in data.items():\n",
    "    for sentence, actions, tree in d:\n",
    "        test_parser = ShiftReduceParser()\n",
    "        test_parser.initialize_with_sentence(sentence)\n",
    "        for action in actions:\n",
    "            test_parser.step(action)\n",
    "        assert test_parser.done()\n",
    "        assert test_parser.return_parse() == tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc470a0d-5c41-4bbd-a6a6-fc51a4b5949b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell E\n",
    "# trainer class\n",
    "# Q1: What do the \"dependency\" metrics measure?\n",
    "# Q1: You do not need to explain what precision, recall and F1 are,\n",
    "# Q1: but you do need to explain what sets they are computed against.\n",
    "\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class Metrics:\n",
    "    def __init__(self):\n",
    "        self.exact_match = None\n",
    "        self.edit_distance = None\n",
    "        self.precision = None\n",
    "        self.recall = None\n",
    "        self.f1 = None\n",
    "\n",
    "    def reset(self):\n",
    "        self.exact_match = []\n",
    "        self.edit_distance = []\n",
    "        self.subtree_precision = []\n",
    "        self.subtree_recall = []\n",
    "        self.subtree_f1 = []\n",
    "        self.dependency_precision = []\n",
    "        self.dependency_recall = []\n",
    "        self.dependency_f1 = []\n",
    "\n",
    "    def overlap(self, forest1, forest2):\n",
    "        counter = 0\n",
    "        # candidate in forest1 can only match once\n",
    "        for t1 in forest1:\n",
    "            for t2 in forest2:\n",
    "                if t1 == t2:\n",
    "                    counter += 1\n",
    "                    break\n",
    "        return counter\n",
    "\n",
    "    def levenshtein_distance(self, a, b):\n",
    "        output = {}\n",
    "        assert isinstance(a, list)\n",
    "        assert isinstance(b, list)\n",
    "        for ii in range(1 + len(a)):\n",
    "            output[(ii, 0)] = ii\n",
    "            for jj in range(1 + len(b)):\n",
    "                output[(0, jj)] = jj\n",
    "                if ii and jj:\n",
    "                    output[(ii, jj)] = min(\n",
    "                        output[(ii - 1, jj)] + 1,\n",
    "                        output[(ii, jj - 1)] + 1,\n",
    "                        output[(ii - 1, jj - 1)] + int(a[ii - 1] != b[jj - 1]),\n",
    "                    )\n",
    "        return output[(len(a), len(b))]\n",
    "\n",
    "    def record_sequences(self, predictions, gold_sequences):\n",
    "        assert len(predictions) == len(gold_sequences)\n",
    "\n",
    "        def is_list_of_list_of_str(x):\n",
    "            output = isinstance(x, list)\n",
    "            for y in x:\n",
    "                output &= isinstance(y, list)\n",
    "                for z in y:\n",
    "                    output &= isinstance(z, str)\n",
    "            return output\n",
    "\n",
    "        assert is_list_of_list_of_str(gold_sequences), gold_sequences\n",
    "        assert is_list_of_list_of_str(predictions), predictions\n",
    "        for p, g in zip(predictions, gold_sequences):\n",
    "            self.edit_distance.append(self.levenshtein_distance(p, g) / len(g))\n",
    "\n",
    "    def all_links(self, tree):\n",
    "        assert isinstance(tree, str) or isinstance(tree, ntree.Tree)\n",
    "        if isinstance(tree, str):\n",
    "            return []\n",
    "        elif len(tree) == 0:\n",
    "            return []\n",
    "        else:\n",
    "            output = [\n",
    "                (tree.label(), child if isinstance(child, str) else child.label())\n",
    "                for child in tree\n",
    "            ]\n",
    "            for child in tree:\n",
    "                output.extend(self.all_links(child))\n",
    "            return output\n",
    "\n",
    "    def record_trees(self, predictions, gold_references):\n",
    "        assert len(predictions) == len(gold_references)\n",
    "        assert all(isinstance(g, ntree.Tree) for g in gold_references)\n",
    "        assert all(isinstance(p, ntree.Tree) for p in predictions), predictions\n",
    "        for p, g in zip(predictions, gold_references):\n",
    "            self.exact_match.append(int(p == g))\n",
    "            # dependencies\n",
    "            ps = self.all_links(p)\n",
    "            gs = self.all_links(g)\n",
    "            assert gs\n",
    "            ncp = self.overlap(ps, gs)  # number correct precision\n",
    "            ncr = self.overlap(gs, ps)  # number correct recall\n",
    "            lps = max(1, len(ps))\n",
    "            lgs = max(1, len(gs))\n",
    "            self.dependency_precision.append(ncp / lps)\n",
    "            self.dependency_recall.append(ncr / lgs)\n",
    "            f1 = 0\n",
    "            if ncr or ncp:\n",
    "                f1 = 2 * ncp * ncr / (lps * ncr + lgs * ncp)\n",
    "            self.dependency_f1.append(f1)\n",
    "            # subtrees\n",
    "            ps = list(p.subtrees())\n",
    "            gs = list(g.subtrees())\n",
    "            assert ps\n",
    "            assert gs\n",
    "            ncp = self.overlap(ps, gs)  # number correct precision\n",
    "            ncr = self.overlap(gs, ps)  # number correct recall\n",
    "            lps = max(1, len(ps))\n",
    "            lgs = max(1, len(gs))\n",
    "            self.subtree_precision.append(ncp / lps)\n",
    "            self.subtree_recall.append(ncr / lgs)\n",
    "            f1 = 0\n",
    "            if ncr or ncp:\n",
    "                f1 = 2 * ncp * ncr / (lps * ncr + lgs * ncp)\n",
    "            self.subtree_f1.append(f1)\n",
    "\n",
    "    def get_metrics(self):\n",
    "        def mean(l):\n",
    "            return sum(l) / len(l)\n",
    "\n",
    "        output = {\n",
    "            \"exact match\": mean(self.exact_match),\n",
    "            \"dependency precision\": mean(self.dependency_precision),\n",
    "            \"dependency recall\": mean(self.dependency_recall),\n",
    "            \"dependency f1\": mean(self.dependency_f1),\n",
    "            \"subtree precision\": mean(self.subtree_precision),\n",
    "            \"subtree recall\": mean(self.subtree_recall),\n",
    "            \"subtree f1\": mean(self.subtree_f1),\n",
    "            \"edit distance\": mean(self.edit_distance),\n",
    "            \"N\": {\n",
    "                \"exact match\": len(self.exact_match),\n",
    "                \"dependency precision\": len(self.dependency_precision),\n",
    "                \"dependency recall\": len(self.dependency_recall),\n",
    "                \"dependency f1\": len(self.dependency_f1),\n",
    "                \"subtree precision\": len(self.subtree_precision),\n",
    "                \"subtree recall\": len(self.subtree_recall),\n",
    "                \"subtree f1\": len(self.subtree_f1),\n",
    "                \"edit distance\": len(self.edit_distance),\n",
    "            },\n",
    "        }\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfd0001",
   "metadata": {},
   "source": [
    "**Cell E Q1: What do the \"dependency\" metrics measure? You do not need to explain what precision, recall and F1 are, but you do need to explain what sets they are computed against.**\n",
    "\n",
    "The dependency metrics evaluate how closely the predicted tree’s dependency links align with those in the gold (reference) tree.\n",
    "\n",
    "Dependency precision measures the proportion of links in the predicted set that also exist in the gold set, while dependency recall quantifies the proportion of gold set links that are correctly identified in the predicted set. The F1 score is calculated as the harmonic mean of precision and recall.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3f8ead5-3a39-4b82-aa77-3deac827a522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell F\n",
    "# BM25 retriever\n",
    "# Q2: What is BM25? How does this retriever work?\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "\n",
    "class FewShotRetriever:\n",
    "    def __init__(self, data_set):\n",
    "        # data_set contains items from the training set\n",
    "        assert isinstance(data_set, list)\n",
    "        assert all(isinstance(x, tuple) for x in data_set)\n",
    "        self.data = [(x[0], x[1]) for x in data_set]\n",
    "        self.bm25 = None\n",
    "\n",
    "    def build_index(self):\n",
    "        self.corpus = [x[0] for x in self.data]\n",
    "        self.bm25 = BM25Okapi(self.corpus)\n",
    "\n",
    "    def get_samples(self, query, n=4):\n",
    "        tokenized_query = query.split(\" \")\n",
    "        top_n = self.bm25.get_top_n(tokenized_query, self.data, n=n)\n",
    "        return top_n\n",
    "\n",
    "\n",
    "# build retriever on training data\n",
    "retriever = FewShotRetriever(data[\"train\"])\n",
    "retriever.build_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fcf85a",
   "metadata": {},
   "source": [
    "**Cell F Q2: What is BM25? How does this retriever work?**\n",
    "\n",
    "BM25 (Best Matching 25) is a ranking function used in information retrieval to score documents based on their relevance to a given query.\n",
    "The BM25 algorithm is an improved version of the TF-IDF algorithm. It uses TF (Term Frequency), IDF (Inverse Document Frequency) and Document Length Normalization to calculate the relevance of a document to a query.\n",
    "\n",
    "The FewShotRetriever class is designed to find the most relevant examples from a dataset using BM25.\n",
    "\n",
    "With the `build_index` method, the retriever creates the corpus: a collection of all the inputs of the dataset. This corpus will be then given to the BM25 algorithm to build the index.\n",
    "\n",
    "The `get_samples` method is used to find the most relevant examples from the dataset given a query. It returns the top_n examples with the highest BM25 scores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f61d6167-5e8b-499e-8348-d3e7bd02c2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell G\n",
    "import numpy as np\n",
    "import scipy.stats as sh\n",
    "\n",
    "\n",
    "def valid_estimate(records):\n",
    "    assert isinstance(records, list)\n",
    "    assert len(records) > 0\n",
    "    assert all(isinstance(x, float) for x in records)\n",
    "    mu = np.mean(records)\n",
    "    interval = sh.t.interval(\n",
    "        confidence=0.9, df=len(records) - 1, loc=mu, scale=sh.sem(records)\n",
    "    )\n",
    "    criterion = (interval[1] - interval[0]) < 0.1\n",
    "\n",
    "    if criterion:\n",
    "        print(\n",
    "            \"mean: {:.3f}, interval: [{:.3f}, {:.3f}]\".format(\n",
    "                mu, interval[0], interval[1]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37c242ba-843b-4a40-b53a-5eecc5df418a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell H\n",
    "# LLM parser\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "import json\n",
    "\n",
    "\n",
    "class LLMParser:\n",
    "    def __init__(self, model_name, retriever, n_few_shot=2, max_tokens=100):\n",
    "        assert isinstance(retriever, FewShotRetriever)\n",
    "        self.retriever = retriever\n",
    "        assert isinstance(max_tokens, int)\n",
    "        self.max_tokens = max_tokens\n",
    "        assert isinstance(model_name, str)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name, pad_token_id=self.tokenizer.eos_token_id\n",
    "        )\n",
    "        assert isinstance(n_few_shot, int)\n",
    "        self.n_few_shot = n_few_shot\n",
    "\n",
    "    def generate(self, input_strings):\n",
    "        assert isinstance(input_strings, list)\n",
    "        assert len(input_strings) > 0\n",
    "        assert all(isinstance(ii, str) for ii in input_strings)\n",
    "        prompts = self.make_prompts(input_strings)\n",
    "        pipe = pipeline(\n",
    "            \"text-generation\",\n",
    "            model=self.model,\n",
    "            tokenizer=self.tokenizer,\n",
    "            device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "        )\n",
    "        generation_args = {\n",
    "            \"max_new_tokens\": self.max_tokens,\n",
    "            \"return_full_text\": False,\n",
    "            \"do_sample\": False,\n",
    "            \"stop_strings\": [\"\\n\"],\n",
    "            \"tokenizer\": self.tokenizer,\n",
    "            \"pad_token_id\": self.tokenizer.eos_token_id,\n",
    "        }\n",
    "        output = pipe(prompts, **generation_args)\n",
    "        output = [oo[0] for oo in output]\n",
    "        assert len(output) == len(prompts)\n",
    "        output = [\n",
    "            {\"prompt\": prompt, \"lm_output\": x[\"generated_text\"]}\n",
    "            for x, prompt in zip(output, prompts)\n",
    "        ]\n",
    "        return output\n",
    "\n",
    "    def make_prompt(self, input_string):\n",
    "        samples = self.retriever.get_samples(input_string, n=self.n_few_shot)\n",
    "        # assert len(samples) == self.n_few_shot\n",
    "        prompt = [\"{}\\n{}\".format(\" \".join(x), \" \".join(y)) for x, y in samples]\n",
    "        prompt.append(\"{}\\n\".format(input_string))\n",
    "        prompt = \"\\n\".join(prompt)\n",
    "        return prompt\n",
    "\n",
    "    def make_prompts(self, input_strings):\n",
    "        prompts = [self.make_prompt(input_string) for input_string in input_strings]\n",
    "        return prompts\n",
    "\n",
    "    def eval(self, data, batch_size=16, variable_size=False):\n",
    "        if variable_size:\n",
    "            return self.eval_variable_size(data, batch_size=batch_size)\n",
    "        metrics = Metrics()\n",
    "        metrics.reset()\n",
    "        for position in tqdm(range(0, len(data), batch_size)):\n",
    "            chunk = data[position : position + batch_size]\n",
    "            assert len(chunk) > 0\n",
    "            # chunk is a list of tuples (input_seq, action_seq, tree)\n",
    "            self.eval_step(chunk, metrics)\n",
    "        return metrics.get_metrics()\n",
    "\n",
    "    def eval_variable_size(self, data, batch_size=16):\n",
    "        metrics = Metrics()\n",
    "        metrics.reset()\n",
    "        position = 0\n",
    "        terminate = False\n",
    "        while (position < len(data)) and (not terminate):\n",
    "            chunk = data[position : position + batch_size]\n",
    "            assert len(chunk) > 0\n",
    "            # chunk is a list of tuples (input_seq, action_seq, tree)\n",
    "            self.eval_step(chunk, metrics)\n",
    "            position += batch_size\n",
    "            terminate = valid_estimate(metrics.edit_distance)\n",
    "        return metrics.get_metrics()\n",
    "\n",
    "    def eval_step(self, chunk, metrics):\n",
    "        # chunk is a list of tuples (input_seq, action_seq, tree)\n",
    "        sentences = [\n",
    "            \" \".join(x[0]) for x in chunk\n",
    "        ]  # this is a very basic form of detokenization\n",
    "        y = self.generate(sentences)\n",
    "        generated_sequences = [x[\"lm_output\"].split() for x in y]\n",
    "        metrics.record_sequences(generated_sequences, [x[1] for x in chunk])\n",
    "        trees = []\n",
    "        for ii, sentence in enumerate(sentences):\n",
    "            parser = ShiftReduceParser()\n",
    "            parser.initialize_with_sentence(sentence.split())\n",
    "            for action in generated_sequences[ii]:\n",
    "                parser.step(action)\n",
    "            trees.append(parser.return_parse(force=True))\n",
    "        assert len(trees) == len(chunk)\n",
    "        metrics.record_trees(trees, [x[2] for x in chunk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22357cda-b2a0-409c-a1a9-dc37314dbef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluating Model: Qwen/Qwen2.5-1.5B ===\n",
      "\n",
      "=== 0-Shot ===\n",
      "mean: 0.997, interval: [0.995, 0.999]\n",
      "{\n",
      "  \"metrics\": {\n",
      "    \"exact match\": 0.0,\n",
      "    \"dependency precision\": 0.0,\n",
      "    \"dependency recall\": 0.0,\n",
      "    \"dependency f1\": 0.0,\n",
      "    \"subtree precision\": 0.0,\n",
      "    \"subtree recall\": 0.0,\n",
      "    \"subtree f1\": 0.0,\n",
      "    \"edit distance\": 0.9970198101954588,\n",
      "    \"N\": {\n",
      "      \"exact match\": 16,\n",
      "      \"dependency precision\": 16,\n",
      "      \"dependency recall\": 16,\n",
      "      \"dependency f1\": 16,\n",
      "      \"subtree precision\": 16,\n",
      "      \"subtree recall\": 16,\n",
      "      \"subtree f1\": 16,\n",
      "      \"edit distance\": 16\n",
      "    }\n",
      "  },\n",
      "  \"flops_per_sentence (GFLOP)\": 61.754372212\n",
      "}\n",
      "\n",
      "=== 1-Shot ===\n",
      "mean: 0.847, interval: [0.801, 0.893]\n",
      "{\n",
      "  \"metrics\": {\n",
      "    \"exact match\": 0.0,\n",
      "    \"dependency precision\": 0.16867933223398582,\n",
      "    \"dependency recall\": 0.0518067233423056,\n",
      "    \"dependency f1\": 0.07133723491715335,\n",
      "    \"subtree precision\": 0.03918931640971115,\n",
      "    \"subtree recall\": 0.008796309940568453,\n",
      "    \"subtree f1\": 0.012932719250520308,\n",
      "    \"edit distance\": 0.8467094026410223,\n",
      "    \"N\": {\n",
      "      \"exact match\": 48,\n",
      "      \"dependency precision\": 48,\n",
      "      \"dependency recall\": 48,\n",
      "      \"dependency f1\": 48,\n",
      "      \"subtree precision\": 48,\n",
      "      \"subtree recall\": 48,\n",
      "      \"subtree f1\": 48,\n",
      "      \"edit distance\": 48\n",
      "    }\n",
      "  },\n",
      "  \"flops_per_sentence (GFLOP)\": 61.754372212\n",
      "}\n",
      "\n",
      "=== 2-Shot ===\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 43\u001b[0m\n\u001b[1;32m     41\u001b[0m llm_parser \u001b[38;5;241m=\u001b[39m LLMParser(model_name, retriever)\n\u001b[1;32m     42\u001b[0m llm_parser\u001b[38;5;241m.\u001b[39mn_few_shot \u001b[38;5;241m=\u001b[39m n_few_shot\n\u001b[0;32m---> 43\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[43mllm_parser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariable_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Sample an input sentence from test data\u001b[39;00m\n\u001b[1;32m     46\u001b[0m sentence \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\n",
      "Cell \u001b[0;32mIn[8], line 63\u001b[0m, in \u001b[0;36mLLMParser.eval\u001b[0;34m(self, data, batch_size, variable_size)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meval\u001b[39m(\u001b[38;5;28mself\u001b[39m, data, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, variable_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m variable_size:\n\u001b[0;32m---> 63\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_variable_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m Metrics()\n\u001b[1;32m     65\u001b[0m     metrics\u001b[38;5;241m.\u001b[39mreset()\n",
      "Cell \u001b[0;32mIn[8], line 82\u001b[0m, in \u001b[0;36mLLMParser.eval_variable_size\u001b[0;34m(self, data, batch_size)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(chunk) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# chunk is a list of tuples (input_seq, action_seq, tree)\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m position \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_size\n\u001b[1;32m     84\u001b[0m terminate \u001b[38;5;241m=\u001b[39m valid_estimate(metrics\u001b[38;5;241m.\u001b[39medit_distance)\n",
      "Cell \u001b[0;32mIn[8], line 92\u001b[0m, in \u001b[0;36mLLMParser.eval_step\u001b[0;34m(self, chunk, metrics)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meval_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, chunk, metrics):\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;66;03m# chunk is a list of tuples (input_seq, action_seq, tree)\u001b[39;00m\n\u001b[1;32m     89\u001b[0m     sentences \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     90\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(x[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m chunk\n\u001b[1;32m     91\u001b[0m     ]  \u001b[38;5;66;03m# this is a very basic form of detokenization\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentences\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m     generated_sequences \u001b[38;5;241m=\u001b[39m [x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlm_output\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msplit() \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m y]\n\u001b[1;32m     94\u001b[0m     metrics\u001b[38;5;241m.\u001b[39mrecord_sequences(generated_sequences, [x[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m chunk])\n",
      "Cell \u001b[0;32mIn[8], line 40\u001b[0m, in \u001b[0;36mLLMParser.generate\u001b[0;34m(self, input_strings)\u001b[0m\n\u001b[1;32m     26\u001b[0m pipe \u001b[38;5;241m=\u001b[39m pipeline(\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-generation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     28\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel,\n\u001b[1;32m     29\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer,\n\u001b[1;32m     30\u001b[0m     device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     31\u001b[0m )\n\u001b[1;32m     32\u001b[0m generation_args \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_new_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_tokens,\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn_full_text\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpad_token_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39meos_token_id,\n\u001b[1;32m     39\u001b[0m }\n\u001b[0;32m---> 40\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgeneration_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m output \u001b[38;5;241m=\u001b[39m [oo[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m oo \u001b[38;5;129;01min\u001b[39;00m output]\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(output) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(prompts)\n",
      "File \u001b[0;32m~/IA327-Generative-Models-for-NLP/venv/lib/python3.10/site-packages/transformers/pipelines/text_generation.py:272\u001b[0m, in \u001b[0;36mTextGenerationPipeline.__call__\u001b[0;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(chats, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 272\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtext_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/IA327-Generative-Models-for-NLP/venv/lib/python3.10/site-packages/transformers/pipelines/base.py:1283\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m can_use_iterator:\n\u001b[1;32m   1280\u001b[0m     final_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[1;32m   1281\u001b[0m         inputs, num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001b[1;32m   1282\u001b[0m     )\n\u001b[0;32m-> 1283\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfinal_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n\u001b[1;32m   1285\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/IA327-Generative-Models-for-NLP/venv/lib/python3.10/site-packages/transformers/pipelines/pt_utils.py:124\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_item()\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(item, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "File \u001b[0;32m~/IA327-Generative-Models-for-NLP/venv/lib/python3.10/site-packages/transformers/pipelines/pt_utils.py:125\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[1;32m    124\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator)\n\u001b[0;32m--> 125\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;66;03m# Try to infer the size of the batch\u001b[39;00m\n",
      "File \u001b[0;32m~/IA327-Generative-Models-for-NLP/venv/lib/python3.10/site-packages/transformers/pipelines/base.py:1209\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1207\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[1;32m   1208\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m-> 1209\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1210\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   1211\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/IA327-Generative-Models-for-NLP/venv/lib/python3.10/site-packages/transformers/pipelines/text_generation.py:370\u001b[0m, in \u001b[0;36mTextGenerationPipeline._forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration_config\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m generate_kwargs:\n\u001b[1;32m    368\u001b[0m     generate_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration_config\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeneration_config\n\u001b[0;32m--> 370\u001b[0m generated_sequence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    371\u001b[0m out_b \u001b[38;5;241m=\u001b[39m generated_sequence\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/IA327-Generative-Models-for-NLP/venv/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/IA327-Generative-Models-for-NLP/venv/lib/python3.10/site-packages/transformers/generation/utils.py:2215\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2207\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2208\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2209\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2210\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2211\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2212\u001b[0m     )\n\u001b[1;32m   2214\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2215\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2216\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2218\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2219\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2220\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2221\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2222\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2223\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2225\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2226\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   2227\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   2228\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   2229\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2234\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   2235\u001b[0m     )\n",
      "File \u001b[0;32m~/IA327-Generative-Models-for-NLP/venv/lib/python3.10/site-packages/transformers/generation/utils.py:3206\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3203\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[1;32m   3205\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 3206\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3208\u001b[0m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[1;32m   3209\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_kwargs_for_generation(\n\u001b[1;32m   3210\u001b[0m     outputs,\n\u001b[1;32m   3211\u001b[0m     model_kwargs,\n\u001b[1;32m   3212\u001b[0m     is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   3213\u001b[0m )\n",
      "File \u001b[0;32m~/IA327-Generative-Models-for-NLP/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/IA327-Generative-Models-for-NLP/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/IA327-Generative-Models-for-NLP/venv/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py:1164\u001b[0m, in \u001b[0;36mQwen2ForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, num_logits_to_keep, **loss_kwargs)\u001b[0m\n\u001b[1;32m   1161\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1163\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1164\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1165\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1166\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1167\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1168\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1169\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1170\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1171\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1172\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1173\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1177\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1178\u001b[0m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "File \u001b[0;32m~/IA327-Generative-Models-for-NLP/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/IA327-Generative-Models-for-NLP/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/IA327-Generative-Models-for-NLP/venv/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py:895\u001b[0m, in \u001b[0;36mQwen2Model.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    883\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    884\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    885\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    892\u001b[0m         position_embeddings,\n\u001b[1;32m    893\u001b[0m     )\n\u001b[1;32m    894\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 895\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    901\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    903\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    904\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    906\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/IA327-Generative-Models-for-NLP/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/IA327-Generative-Models-for-NLP/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/IA327-Generative-Models-for-NLP/venv/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py:623\u001b[0m, in \u001b[0;36mQwen2DecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    620\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 623\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    633\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    635\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[0;32m~/IA327-Generative-Models-for-NLP/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/IA327-Generative-Models-for-NLP/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/IA327-Generative-Models-for-NLP/venv/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py:502\u001b[0m, in \u001b[0;36mQwen2SdpaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings)\u001b[0m\n\u001b[1;32m    499\u001b[0m bsz, q_len, _ \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39msize()\n\u001b[1;32m    501\u001b[0m query_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_proj(hidden_states)\n\u001b[0;32m--> 502\u001b[0m key_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mk_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    503\u001b[0m value_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_proj(hidden_states)\n\u001b[1;32m    505\u001b[0m query_states \u001b[38;5;241m=\u001b[39m query_states\u001b[38;5;241m.\u001b[39mview(bsz, q_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/IA327-Generative-Models-for-NLP/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/IA327-Generative-Models-for-NLP/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/IA327-Generative-Models-for-NLP/venv/lib/python3.10/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Cell I\n",
    "# TODO report 90% confidence interval. See function \"valid_estimate\" in cell G\n",
    "\n",
    "import torch.profiler\n",
    "\n",
    "models = [\n",
    "    \"Qwen/Qwen2.5-1.5B\",\n",
    "    \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\n",
    "    \"HuggingFaceTB/SmolLM-135M\",\n",
    "]\n",
    "\n",
    "\n",
    "def profile_flops(model, inputs):\n",
    "    with torch.profiler.profile(\n",
    "        activities=[\n",
    "            torch.profiler.ProfilerActivity.CPU,\n",
    "            torch.profiler.ProfilerActivity.CUDA,\n",
    "        ],\n",
    "        record_shapes=True,\n",
    "        profile_memory=True,\n",
    "        with_flops=True,\n",
    "    ) as prof:\n",
    "        with torch.no_grad():\n",
    "            model(**inputs)\n",
    "\n",
    "    total_flops = sum(\n",
    "        [evt.flops for evt in prof.key_averages() if evt.flops is not None]\n",
    "    )\n",
    "    return total_flops\n",
    "\n",
    "\n",
    "for model_name in models:\n",
    "    print(f\"\\n=== Evaluating Model: {model_name} ===\")\n",
    "\n",
    "    for n_few_shot in [0, 1, 2, 4, 8, 16]:\n",
    "        print(f\"\\n=== {n_few_shot}-Shot ===\")\n",
    "\n",
    "        llm_parser = LLMParser(model_name, retriever)\n",
    "        llm_parser.n_few_shot = n_few_shot\n",
    "        metrics = llm_parser.eval(data[\"test\"], variable_size=True)\n",
    "\n",
    "        results = {\n",
    "            \"metrics\": metrics,\n",
    "            \"flops_per_sentence (GFLOP)\": flops_per_sentence / 1e9,\n",
    "        }\n",
    "        print(json.dumps(results, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
